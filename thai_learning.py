# === ç¬¬ä¸€éƒ¨åˆ†ï¼šåˆå§‹åŒ–å’ŒåŸºç¤è¨­å®š ===
import os
import uuid
import random
import json
import firebase_admin
from firebase_admin import credentials, firestore
from datetime import datetime, timedelta
import io
import numpy as np
from pydub import AudioSegment
import requests
import logging
from dotenv import load_dotenv
import random
from difflib import SequenceMatcher
from linebot.models import TextSendMessage, ImageSendMessage, QuickReply, QuickReplyButton, MessageAction



from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, AudioMessage, ImageMessage,
    TextSendMessage, ImageSendMessage, AudioSendMessage,
    TemplateSendMessage, ButtonsTemplate, MessageAction,
    URIAction, QuickReply, QuickReplyButton
)
import azure.cognitiveservices.speech as speechsdk
from google.cloud import storage
from google.cloud import speech
import difflib
import tempfile


from speechbrain.pretrained import SpeakerRecognition

# ===== åˆå§‹åŒ– SpeechBrain æ¨¡å‹ =====
speaker_model = SpeakerRecognition.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    savedir="pretrained_models/spkrec"
)

def compute_similarity(audio1_path, audio2_path):
    """Return similarity score (0~1) between two audio files, using threading for timeout handling"""
    try:
        # ä½¿ç”¨ threading è™•ç†è¶…æ™‚
        import threading
        import time
        
        result = [None]
        error = [None]
        finished = [False]
        
        def process():
            try:
                # åŸ·è¡ŒèªéŸ³æ¯”å°
                score, _ = speaker_model.verify_files(audio1_path, audio2_path)
                result[0] = float(score)
            except Exception as e:
                error[0] = str(e)
            finally:
                finished[0] = True
        
        # å‰µå»ºä¸¦å•Ÿå‹•ç·šç¨‹
        thread = threading.Thread(target=process)
        thread.daemon = True
        thread.start()
        
        # è¨­å®šæœ€é•·ç­‰å¾…æ™‚é–“
        max_wait = 15
        wait_step = 0.5
        waited = 0
        
        while not finished[0] and waited < max_wait:
            time.sleep(wait_step)
            waited += wait_step
        
        if not finished[0]:
            logger.warning(f"SpeechBrain processing timeout ({max_wait}s)")
            return 0.65  # è¿”å›ä¸­ç­‰ç›¸ä¼¼åº¦ä½œç‚ºé è¨­å€¼
        
        if error[0]:
            logger.warning(f"Similarity calculation failed: {error[0]}")
            return 0.65
            
        if result[0] is not None:
            # ç¢ºä¿å€¼åœ¨ 0-1 ç¯„åœå…§
            return max(0, min(1, result[0]))
        
        return 0.65
    except Exception as e:
        logger.warning(f"Overall similarity calculation failed: {str(e)}")
        return 0.65

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åŠ è¼‰ç’°å¢ƒè®Šæ•¸
load_dotenv()  # è¼‰å…¥ .env æ–‡ä»¶ä¸­çš„ç’°å¢ƒè®Šæ•¸ (æœ¬åœ°é–‹ç™¼ç”¨)

# === æ‡‰ç”¨åˆå§‹åŒ– ===
app = Flask(__name__)
exam_sessions = {}  # user_id å°æ‡‰ç›®å‰è€ƒè©¦ç‹€æ…‹
processed_events =  {} 
# LINE Botè¨­å®š
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get('LINE_CHANNEL_ACCESS_TOKEN', 'YOUR_CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.environ.get('LINE_CHANNEL_SECRET', 'YOUR_CHANNEL_SECRET')

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# Azure Speech Servicesè¨­å®š
speech_key = os.environ.get('AZURE_SPEECH_KEY', 'YOUR_AZURE_SPEECH_KEY')
speech_region = os.environ.get('AZURE_SPEECH_REGION', 'eastasia')

# Google Cloud Storage è¨­å®š
GCS_BUCKET_NAME = os.environ.get('GCS_BUCKET_NAME', 'your-thai-learning-bucket')

logger.info(f"Initializing application... LINE Bot, Azure Speech and GCS services configured")

# === Google Cloud Storage è¼”åŠ©å‡½æ•¸ ===

def init_gcs_client():
    """Initialize Google Cloud Storage client"""
    try:
        # å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸ç²å–èªè­‰
        import json
        import tempfile
        
        # 1. é¦–å…ˆå˜—è©¦ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ä¸­çš„ JSON å…§å®¹
        creds_json = os.environ.get('GCS_CREDENTIALS')
        if creds_json:
            # å‰µå»ºè‡¨æ™‚æ–‡ä»¶å­˜å„²æ†‘è­‰
            with tempfile.NamedTemporaryFile(suffix='.json', delete=False) as temp:
                temp.write(creds_json.encode('utf-8'))
                temp_file_name = temp.name
            
            # ä½¿ç”¨è‡¨æ™‚æ–‡ä»¶åˆå§‹åŒ–å®¢æˆ¶ç«¯
            storage_client = storage.Client.from_service_account_json(temp_file_name)
                       
            # ä½¿ç”¨å¾Œåˆªé™¤è‡¨æ™‚æ–‡ä»¶
            os.unlink(temp_file_name)
            logger.info("Successfully initialized Google Cloud Storage client using GCS_CREDENTIALS environment variable")
            return storage_client
            
        # 2. å˜—è©¦ä½¿ç”¨æœ¬åœ°é‡‘é‘°æ–‡ä»¶ (æœ¬åœ°é–‹ç™¼ä½¿ç”¨)
        local_keyfile_path = r"C:\Users\ids\Desktop\æ³°æ–‡å­¸ç¿’çš„è«–æ–‡è³‡æ–™(é™¤äº†)ç¨‹å¼ç›¸é—œ\æ³°æ–‡èŠå¤©æ©Ÿå™¨äººgoogle storage é‡‘é‘°.json"
        if os.path.exists(local_keyfile_path):
            storage_client = storage.Client.from_service_account_json(local_keyfile_path)
            logger.info("ä½¿ç”¨æœ¬åœ°é‡‘é‘°æ–‡ä»¶æˆåŠŸåˆå§‹åŒ– Google Cloud Storage å®¢æˆ¶ç«¯")
            return storage_client
            
        # 3. å˜—è©¦ä½¿ç”¨é»˜èªèªè­‰
        storage_client = storage.Client()
        logger.info("Successfully initialized Google Cloud Storage client using default authentication")
        return storage_client
    
    except Exception as e:
        logger.error(f"Failed to initialize Google Cloud Storage client: {str(e)}")
        return None

def upload_file_to_gcs(file_content, destination_blob_name, content_type=None):
    """Upload file to Google Cloud Storage and return public URL"""
    try:
        # åˆå§‹åŒ– GCS å®¢æˆ¶ç«¯
        storage_client = init_gcs_client()
        if not storage_client:
            logger.error("Unable to initialize GCS client")
            return None
            
        # ç²å– bucket
        bucket = storage_client.bucket(GCS_BUCKET_NAME)
        
        # å‰µå»ºä¸€å€‹æ–°çš„ blob
        blob = bucket.blob(destination_blob_name)
        
        # è¨­ç½®å…§å®¹é¡å‹ï¼ˆå¦‚æœæä¾›ï¼‰
        if content_type:
            blob.content_type = content_type
            
        # ä¸Šå‚³æª”æ¡ˆ
        if hasattr(file_content, 'read'):
            # å¦‚æœæ˜¯æª”æ¡ˆç‰©ä»¶
            blob.upload_from_file(file_content, rewind=True)
        else:
            # å¦‚æœæ˜¯äºŒé€²åˆ¶æ•¸æ“š
            blob.upload_from_string(file_content)
            
        # è¨­ç½®ç‚ºå…¬é–‹å¯è®€å–
        blob.make_public()
        
        # è¿”å›å…¬é–‹ URL
        logger.info(f"Successfully uploaded file to {destination_blob_name}, URL: {blob.public_url}")
        return blob.public_url
        
    except Exception as e:
        logger.error(f"Error uploading file to GCS: {str(e)}")
        return None

# æ¸¬è©¦ Azure èªéŸ³æœå‹™é€£æ¥
def test_azure_connection():
    """Test Azure Speech Services connection"""
    try:
        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)
        logger.info("Azure Speech Services connection test successful")
    except Exception as e:
        logger.error(f"Azure Speech Services connection test failed: {str(e)}")

# åœ¨æ¨¡çµ„å±¤ç´šèª¿ç”¨é€™å€‹å‡½æ•¸
test_azure_connection()

# === LINE Bot Webhook è™•ç† ===
@app.route("/callback", methods=['POST'])
def callback():
    try:
        # å¢åŠ æ›´è©³ç´°çš„éŒ¯èª¤è™•ç†
        signature = request.headers.get('X-Line-Signature', '')
        body = request.get_data(as_text=True)
        
        logger.info(f"Received callback, signature: {signature}")
        logger.info(f"Callback content: {body}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡äº‹ä»¶
        data = json.loads(body)
        if 'events' in data and len(data['events']) > 0:
            event_id = data['events'][0].get('webhookEventId', '')
            if event_id and event_id in processed_events:
                logger.warning(f"Received duplicate event ID: {event_id}ï¼Œignoring")
                return 'OK'
                
            # è¨˜éŒ„å·²è™•ç†çš„äº‹ä»¶
            if event_id:
                processed_events[event_id] = datetime.now()
                
            # æ¸…ç†èˆŠäº‹ä»¶è¨˜éŒ„ï¼Œé¿å…ä½”ç”¨éå¤šè¨˜æ†¶é«”
            if len(processed_events) > 1000:
                now = datetime.now()
                old_keys = [k for k, v in processed_events.items() 
                           if (now - v).total_seconds() > 3600]
                for k in old_keys:
                    processed_events.pop(k, None)
        
        handler.handle(body, signature)
    except InvalidSignatureError as e:
        logger.error(f"Signature verification failed: {str(e)}")
        abort(400)
    except Exception as e:
        logger.error(f"Unknown error occurred while processing callback: {str(e)}")
        abort(500)
    
    return 'OK'
# === ç¬¬äºŒéƒ¨åˆ†ï¼šç”¨æˆ¶æ•¸æ“šç®¡ç†å’Œæ³°èªå­¸ç¿’è³‡æ–™ ===

# === ç”¨æˆ¶æ•¸æ“šç®¡ç† ===
class UserData:
    def __init__(self):
        self.users = {}
        # æ·»åŠ è‡¨æ™‚ç”¨æˆ¶æ•¸æ“šå­˜å„²
        self.users['temp'] = {'game_state': {}}
        logger.info("Initialized user data manager")
        # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œæ‡‰è©²ä½¿ç”¨è³‡æ–™åº«å­˜å„²é€™äº›æ•¸æ“š
        
    def get_user_data(self, user_id):
        """ç²å–ç”¨æˆ¶æ•¸æ“šï¼Œå¦‚æœä¸å­˜åœ¨å‰‡åˆå§‹åŒ–"""
        if user_id not in self.users:
            logger.info(f"Creating data for new user: {user_id}")
            self.users[user_id] = {
                'score': 0,
                'current_activity': None,
                'current_vocab': None,
                'current_category': None,
                'game_state': {},
                'vocab_mastery': {},
                'learning_progress': {},
                'last_active': self.current_date(),
                'streak': 0
            }
        return self.users[user_id]
    
    def current_date(self):
        """Get current date for tracking learning progress"""
        return datetime.now().strftime("%Y-%m-%d")
    
    def update_streak(self, user_id):
        """Update user's consecutive learning days"""
        user_data = self.get_user_data(user_id)
        last_active = datetime.strptime(user_data['last_active'], "%Y-%m-%d")
        today = datetime.now()
        
        if (today - last_active).days == 1:  # é€£çºŒä¸‹ä¸€å¤©å­¸ç¿’
            user_data['streak'] += 1
            logger.info(f"User {user_id}  learning streak increased to  {user_data['streak']} days")
        elif (today - last_active).days > 1:  # ä¸­æ–·äº†é€£çºŒå­¸ç¿’
            user_data['streak'] = 1
            logger.info(f"User {user_id} learning streak interrupted, reset to 1 day")
        # å¦‚æœæ˜¯åŒä¸€å¤©ï¼Œstreakä¿æŒä¸è®Š
        
        user_data['last_active'] = self.current_date()

user_data_manager = UserData()

# === æ³°èªå­¸ç¿’è³‡æ–™ ===
thai_data = {
    'categories': {
        'daily_phrases': {
            'name': 'Daily Phrases',
            'words': ['Hello', 'Thank You', 'Goodbye', 'Sorry', 'Good Morning',
                'Good Night', "You're Welcome", 'How to Get There?', 'How Much?', 'Delicious']
        },
        'numbers': {
            'name': 'Numbers',
            'words': ['One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine', 'Ten']
        },
        'animals': {
            'name': 'Animals',
            'words': ['Cat', 'Dog', 'Bird', 'Fish', 'Elephant', 'Tiger', 'Monkey', 'Chicken', 'Pig', 'Cow']
        },
        'food': {
            'name': 'Food',
            'words': [ 'Rice', 'Noodles', 'Beer', 'Bread', 'Chicken Wings', 'Mango Sticky Rice',
                'Fried Rice', 'Papaya Salad', 'Tom Yum Soup', 'Pad Thai']
        },
        'transportation': {
            'name': 'Transportation',
            'words': [ 'Car', 'Bus', 'Taxi', 'Motorbike', 'Train', 'Airplane',
                'Boat', 'Bicycle', 'Tuk Tuk', 'Truck']
        }
    },
    'basic_words': {
        # æ—¥å¸¸ç”¨èª
        'Hello': {'thai': 'à¸ªà¸§à¸±à¸ªà¸”à¸µ', 'pronunciation': 'sa-wat-dee', 'tone': 'mid-falling-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E4%BD%A0%E5%A5%BD.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/Hello.jpg'},
        'Thank You': {'thai': 'à¸‚à¸­à¸šà¸„à¸¸à¸“', 'pronunciation': 'khop-khun', 'tone': 'low-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E8%AC%9D%E8%AC%9D.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/thank.jpg'},
        'Goodbye': {'thai': 'à¸¥à¸²à¸à¹ˆà¸­à¸™', 'pronunciation': 'la-kon', 'tone': 'mid-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E5%86%8D%E8%A6%8B.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/bye.jpg'},
        'Sorry': {'thai': 'à¸‚à¸­à¹‚à¸—à¸©', 'pronunciation': 'kho-thot', 'tone': 'low-low',
                'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E5%B0%8D%E4%B8%8D%E8%B5%B7.mp3',
                'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/sorry.jpg'},
        'Good Morning': {'thai': 'à¸­à¸£à¸¸à¸“à¸ªà¸§à¸±à¸ªà¸”à¸´à¹Œ', 'pronunciation': 'a-run-sa-wat', 'tone': 'mid-mid-falling-mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E6%97%A9%E5%AE%89.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/morning.jpg'},
        'Good Night': {'thai': 'à¸£à¸²à¸•à¸£à¸µà¸ªà¸§à¸±à¸ªà¸”à¸´à¹Œ', 'pronunciation': 'ra-tree-sa-wat', 'tone': 'mid-mid-falling-mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E6%99%9A%E5%AE%89.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/night.jpg'},
        'You are Welcome': {'thai': 'à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸£', 'pronunciation': 'mai-pen-rai', 'tone': 'mid-mid-mid',
                'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E4%B8%8D%E5%AE%A2%E6%B0%A3.mp3',
                'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/welcome.jpg'},
        'How to Get There': {'thai': 'à¹„à¸›à¸—à¸²à¸‡à¹„à¸«à¸™', 'pronunciation': 'pai-tang-nai', 'tone': 'mid-mid-mid',
                'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E6%80%8E%E9%BA%BC%E8%B5%B0.mp3',
                'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/how%20can%20i%20go%20to.jpg'},
        'How Much?': {'thai': 'à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ', 'pronunciation': 'tao-rai', 'tone': 'mid-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E5%A4%9A%E5%B0%91%E9%8C%A2.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/askprice.jpg'},
        'Delicious': {'thai': 'à¸­à¸£à¹ˆà¸­à¸¢', 'pronunciation': 'a-roi', 'tone': 'mid-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/%E5%A5%BD%E5%90%83.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E6%97%A5%E5%B8%B8%E7%94%A8%E8%AA%9E/yummy.jpg'},
        
        # æ•¸å­—
        'One': {'thai': 'à¸«à¸™à¸¶à¹ˆà¸‡', 'pronunciation': 'neung', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/1.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/1.png'},
        'Two': {'thai': 'à¸ªà¸­à¸‡', 'pronunciation': 'song', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/2.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/2.jpg'},
        'Three': {'thai': 'à¸ªà¸²à¸¡', 'pronunciation': 'sam', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/3.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/3.jpg'},
        'Four': {'thai': 'à¸ªà¸µà¹ˆ', 'pronunciation': 'see', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/4.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/4.jpg'},
        'Five': {'thai': 'à¸«à¹‰à¸²', 'pronunciation': 'ha', 'tone': 'falling',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/5.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/5.jpg'},
        'Six': {'thai': 'à¸«à¸', 'pronunciation': 'hok', 'tone': 'low',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/6.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/6.jpg'},
        'Seven': {'thai': 'à¹€à¸ˆà¹‡à¸”', 'pronunciation': 'jet', 'tone': 'falling',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/7.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/7.jpg'},
        'Eight': {'thai': 'à¹à¸›à¸”', 'pronunciation': 'paet', 'tone': 'falling',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/8.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/8.jpg'},
        'Nine': {'thai': 'à¹€à¸à¹‰à¸²', 'pronunciation': 'kao', 'tone': 'falling',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/9.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/9.jpg'},
        'Ten': {'thai': 'à¸ªà¸´à¸š', 'pronunciation': 'sip', 'tone': 'low',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E6%95%B8%E5%AD%97/10.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E6%95%B8%E5%AD%97/10.jpg'},
        
        # å‹•ç‰©
        'Cat': {'thai': 'à¹à¸¡à¸§', 'pronunciation': 'maew', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E8%B2%93.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E8%B2%93.jpg'},
        'Dog': {'thai': 'à¸«à¸¡à¸²', 'pronunciation': 'ma', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E7%8B%97.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E7%8B%97.jpg'},
        'Bird': {'thai': 'à¸™à¸', 'pronunciation': 'nok', 'tone': 'low',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E9%B3%A5.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E9%B3%A5.jpg'},
        'Fish': {'thai': 'à¸›à¸¥à¸²', 'pronunciation': 'pla', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E9%AD%9A.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E9%AD%9A.jpg'},
        'Elephant': {'thai': 'à¸Šà¹‰à¸²à¸‡', 'pronunciation': 'chang', 'tone': 'high',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E5%A4%A7%E8%B1%A1.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E5%A4%A7%E8%B1%A1.jpg'},
        'Tiger': {'thai': 'à¹€à¸ªà¸·à¸­', 'pronunciation': 'suea', 'tone': 'low',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E8%80%81%E8%99%8E.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E8%80%81%E8%99%8E.jpg'},
        'Monkey': {'thai': 'à¸¥à¸´à¸‡', 'pronunciation': 'ling', 'tone': 'mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E7%8C%B4%E5%AD%90.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E7%8C%B4.jpg'},
        'Chicken': {'thai': 'à¹„à¸à¹ˆ', 'pronunciation': 'kai', 'tone': 'low',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E9%9B%9E.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E9%9B%9E.jpg'},
        'Pig': {'thai': 'à¸«à¸¡à¸¹', 'pronunciation': 'moo', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E8%B1%AC.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E8%B1%AC.jpg'},
        'Cow': {'thai': 'à¸§à¸±à¸§', 'pronunciation': 'wua', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E5%8B%95%E7%89%A9/%E7%89%9B.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E5%8B%95%E7%89%A9/%E7%89%9B.jpg'},
        
        # é£Ÿç‰©
        'Rice': {'thai': 'à¸‚à¹‰à¸²à¸§', 'pronunciation': 'khao', 'tone': 'falling',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E7%B1%B3%E9%A3%AF.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/rice.jpg'},
        'Noodles': {'thai': 'à¸à¹‹à¸§à¸¢à¹€à¸•à¸µà¹‹à¸¢à¸§', 'pronunciation': 'guay-tiew', 'tone': 'falling-falling-low',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E7%B2%BF%E6%A2%9D.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/%E7%B2%BF%E6%A2%9D.jpg'},
        'Beer': {'thai': 'à¹€à¸šà¸µà¸¢à¸£à¹Œ', 'pronunciation': 'bia', 'tone': 'mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E5%95%A4%E9%85%92.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/beer.jpg'},
        'Bread': {'thai': 'à¸‚à¸™à¸¡à¸›à¸±à¸‡', 'pronunciation': 'kha-nom-pang', 'tone': 'mid-mid-mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E9%BA%B5%E5%8C%85.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/bread.jpg'},
        'Chicken Wings': {'thai': 'à¸›à¸µà¸à¹„à¸à¹ˆ', 'pronunciation': 'peek-kai', 'tone': 'falling-low',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E9%9B%9E%E7%BF%85.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/chicken%20wing.jpg'},
        'Mango Sticky Rice': {'thai': 'à¸‚à¹‰à¸²à¸§à¹€à¸«à¸™à¸µà¸¢à¸§à¸¡à¸°à¸¡à¹ˆà¸§à¸‡', 'pronunciation': 'khao-niew-ma-muang', 'tone': 'falling-falling-mid-mid',
                 'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E8%8A%92%E6%9E%9C%E7%B3%AF%E7%B1%B3%E9%A3%AF.mp3',
                 'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/mango%20sticky%20rice.jpg'},
        'Fried Rice': {'thai': 'à¸‚à¹‰à¸²à¸§à¸œà¸±à¸”', 'pronunciation': 'khao-pad', 'tone': 'falling-low',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E7%82%92%E9%A3%AF.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/fried%20rice.jpg'},
        'Papaya Salad': {'thai': 'à¸ªà¹‰à¸¡à¸•à¸³', 'pronunciation': 'som-tam', 'tone': 'falling-mid',
                  'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E9%9D%92%E6%9C%A8%E7%93%9C%E6%B2%99%E6%8B%89.mp3',
                  'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/papaya-salad.jpg'},
        'Tom Yum Soup': {'thai': 'à¸•à¹‰à¸¡à¸¢à¸³à¸à¸¸à¹‰à¸‡', 'pronunciation': 'tom-yum-kung', 'tone': 'high-mid-mid',
                 'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E5%86%AC%E8%94%AD%E5%8A%9F%E6%B9%AF.mp3',
                 'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/tom%20yam%20kung.jpg'},
        'Pad Thai': {'thai': 'à¸œà¸±à¸”à¹„à¸—à¸¢', 'pronunciation': 'pad-thai', 'tone': 'low-mid',
                  'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E9%A3%9F%E7%89%A9/%E6%B3%B0%E5%BC%8F%E7%82%92%E6%B2%B3%E7%B2%89.mp3',
                  'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%A3%9F%E7%89%A9/pad%20tai.jpg'},
        
        # äº¤é€šå·¥å…·
        'Car': {'thai': 'à¸£à¸–à¸¢à¸™à¸•à¹Œ', 'pronunciation': 'rot-yon', 'tone': 'high-mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E8%BB%8A%E5%AD%90.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E6%B1%BD%E8%BB%8A.jpg'},
        'Bus': {'thai': 'à¸£à¸–à¹€à¸¡à¸¥à¹Œ', 'pronunciation': 'rot-mae', 'tone': 'high-mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E5%85%AC%E8%BB%8A.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E5%85%AC%E8%BB%8A.jpg'},
        'Taxi': {'thai': 'à¹à¸—à¹‡à¸à¸‹à¸µà¹ˆ', 'pronunciation': 'taxi', 'tone': 'mid-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E8%A8%88%E7%A8%8B%E8%BB%8A.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E8%A8%88%E7%A8%8B%E8%BB%8A.jpg'},
        'Motorbike': {'thai': 'à¸¡à¸­à¹€à¸•à¸­à¸£à¹Œà¹„à¸‹à¸„à¹Œ', 'pronunciation': 'motor-sai', 'tone': 'mid-mid-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E6%91%A9%E6%89%98%E8%BB%8A.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E6%91%A9%E6%89%98%E8%BB%8A.jpg'},
        'Train': {'thai': 'à¸£à¸–à¹„à¸Ÿ', 'pronunciation': 'rot-fai', 'tone': 'high-mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E7%81%AB%E8%BB%8A.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E7%81%AB%E8%BB%8A.jpg'},
        'Airplane': {'thai': 'à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸šà¸´à¸™', 'pronunciation': 'krueang-bin', 'tone': 'falling-mid',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E9%A3%9B%E6%A9%9F.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E9%A3%9B%E6%A9%9F.jpg'},
        'Boat': {'thai': 'à¹€à¸£à¸·à¸­', 'pronunciation': 'ruea', 'tone': 'mid',
             'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E8%88%B9.mp3',
             'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E8%88%B9.jpg'},
        'Bicycle': {'thai': 'à¸ˆà¸±à¸à¸£à¸¢à¸²à¸™', 'pronunciation': 'jak-ka-yan', 'tone': 'low-low-mid',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E8%85%B3%E8%B8%8F%E8%BB%8A.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E8%85%B3%E8%B8%8F%E8%BB%8A.jpg'},
        'Tuk Tuk': {'thai': 'à¸•à¸¸à¹Šà¸à¸•à¸¸à¹Šà¸', 'pronunciation': 'tuk-tuk', 'tone': 'high-high',
               'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E5%98%9F%E5%98%9F%E8%BB%8A.mp3',
               'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E5%98%9F%E5%98%9F%E8%BB%8A.jpg'},
        'Truck': {'thai': 'à¸£à¸–à¸šà¸£à¸£à¸—à¸¸à¸', 'pronunciation': 'rot-ban-tuk', 'tone': 'high-mid-low',
              'audio_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E9%9F%B3%E6%AA%94/%E4%BA%A4%E9%80%9A%E5%B7%A5%E5%85%B7/%E8%B2%A8%E8%BB%8A.mp3',
              'image_url': 'https://storage.googleapis.com/thai_chatbot/%E6%B3%B0%E6%96%87%E6%95%99%E5%AD%B8%E5%9C%96%E5%BA%AB/%E5%9C%96%E7%89%87%E9%81%8B%E8%BC%B8%E5%B7%A5%E5%85%B7/%E8%B2%A8%E8%BB%8A.jpg'}
    },
    'tone_guide': {
        'mid': 'Mid Tone â€“ A stable, even tone',
        'low': 'Low Tone â€“ Pronounced with a lower pitch',
        'falling': 'Falling Tone â€“ Starts high and drops',
        'high': 'High Tone â€“ Pronounced with a higher pitch',
        'rising': 'Rising Tone â€“ Starts low and rises'
    },
    'tone_examples': [
        {'thai': 'à¸„à¸²', 'meaning': 'stick', 'tone': 'mid', 'pronunciation': 'ka (stable tone)'},
        {'thai': 'à¸„à¹ˆà¸²', 'meaning': 'Value', 'tone': 'low', 'pronunciation': 'kÃ  (low tone)'},
        {'thai': 'à¸„à¹‰à¸²', 'meaning': 'Trade', 'tone': 'falling', 'pronunciation': 'kÃ¢ (falling tone)'},
        {'thai': 'à¸„à¹Šà¸²', 'meaning': '(Polite particle)', 'tone': 'high', 'pronunciation': 'kÃ¡ (high tone)'},
        {'thai': 'à¸„à¹‹à¸²', 'meaning': '(No specific meaning)', 'tone': 'rising', 'pronunciation': 'kÇ (rising tone)'}
    ],
    'daily_lessons': [
        {
            'day': 1, 
            'theme': 'åŸºæœ¬å•å€™',
            'words': ['ä½ å¥½', 'è¬è¬', 'å†è¦‹'],
            'dialogue': None
        },
        {
            'day': 2, 
            'theme': 'åŸºæœ¬ç¦®è²Œç”¨èª',
            'words': ['å°ä¸èµ·', 'è¬è¬', 'ä¸å®¢æ°£'],
            'dialogue': None
        },
        {
            'day': 3, 
            'theme': 'è³¼ç‰©çŸ­èª',
            'words': ['å¤šå°‘éŒ¢', 'å¥½åƒ', 'è¬è¬'],
            'dialogue': None
        }
    ]
}

logger.info("å·²è¼‰å…¥æ³°èªå­¸ç¿’è³‡æ–™")
# === ç¬¬ä¸‰éƒ¨åˆ†ï¼šéŸ³é »è™•ç†å’ŒèªéŸ³è©•ä¼°åŠŸèƒ½ ===

# === è¼”åŠ©å‡½æ•¸ ===
def get_audio_content(message_id):
    """å¾LINEå–å¾—éŸ³è¨Šå…§å®¹"""
    logger.info(f"Getting audio content, message ID: {message_id}")
    message_content = line_bot_api.get_message_content(message_id)
    audio_content = b''
    for chunk in message_content.iter_content():
        audio_content += chunk
    return audio_content



def process_audio_content_with_gcs(audio_content, user_id):
    """è™•ç†éŸ³é »å…§å®¹ä¸¦ä¸Šå‚³åˆ° GCS"""
    try:
        # å‰µå»ºè‡¨æ™‚ç›®éŒ„
        temp_dir = os.environ.get('TEMP', '/tmp')
        audio_dir = os.path.join(temp_dir, 'temp_audio')
        os.makedirs(audio_dir, exist_ok=True)
        
        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
        audio_id = f"{user_id}_{uuid.uuid4()}"
        temp_m4a = os.path.join(audio_dir, f'temp_{audio_id}.m4a')
        temp_wav = os.path.join(audio_dir, f'temp_{audio_id}.wav')
        
        logger.info(f"Saving original audio to {temp_m4a}")
        # ä¿å­˜åŸå§‹éŸ³é »
        with open(temp_m4a, 'wb') as f:
            f.write(audio_content)
        
        logger.info("Converting audio format using pydub")
        # ä½¿ç”¨ pydub è½‰æ›æ ¼å¼
        audio = AudioSegment.from_file(temp_m4a)
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(temp_wav, format='wav')
        
        # ç¢ºèª WAV æª”æ¡ˆå·²æˆåŠŸå‰µå»º
        if not os.path.exists(temp_wav):
            logger.error(f"WAV file creation failed: {temp_wav}")
            return None, None
            
        logger.info(f"Audio conversion successful, WAV file path: {temp_wav}")
            
        # ä¸Šå‚³åˆ° GCS
        gcs_path = f"user_audio/{audio_id}.wav"
        
        # é‡æ–°æ‰“é–‹æª”æ¡ˆç”¨æ–¼ä¸Šå‚³ï¼ˆç¢ºä¿æª”æ¡ˆæŒ‡é‡åœ¨èµ·å§‹ä½ç½®ï¼‰
        with open(temp_wav, 'rb') as wav_file:
            public_url = upload_file_to_gcs(wav_file, gcs_path, "audio/wav")
        
        # æ¸…é™¤è‡¨æ™‚æ–‡ä»¶ï¼ˆä¸è¦æ¸…é™¤ temp_wavï¼Œå› ç‚ºå¾ŒçºŒéœ€è¦ä½¿ç”¨ï¼‰
        try:
            os.remove(temp_m4a)
            logger.info(f"Temporary file removed {temp_m4a}")
        except Exception as e:
            logger.warning(f"Failed to remove temporary file: {str(e)}")
            pass
        
        # å¦‚æœ GCS ä¸Šå‚³å¤±æ•—ï¼Œè¿”å›æœ¬åœ°è·¯å¾‘ä»èˆŠæœ‰æ•ˆ
        return public_url, temp_wav
    except Exception as e:
        logger.error(f"Audio processing error: {str(e)}")
        return None, None
    
    
def evaluate_pronunciation(audio_file_path, reference_text, language=""):  # æ”¹ç‚ºç©ºå­—ç¬¦ä¸²
    """ä½¿ç”¨Azure Speech Servicesé€²è¡Œç™¼éŸ³è©•ä¼°"""
    try:
        logger.info(f"Starting pronunciation evaluation, reference text: {reference_text}, audio file: {audio_file_path}")
        
        # ç¢ºèªæª”æ¡ˆå­˜åœ¨
        if not os.path.exists(audio_file_path):
            logger.error(f"Audio file not found: {audio_file_path}")
            return {
                "success": False,
                "error": f"Audio file not found: {audio_file_path}"
            }
            
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size = os.path.getsize(audio_file_path)
        logger.info(f"Audio file size: {file_size} bytes")
        if file_size == 0:
            logger.error("Audio file is empty")
            return {
                "success": False,
                "error": "Audio file is empty"
            }
            
        # è¨­å®šèªéŸ³é…ç½®
        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)
        speech_config.speech_recognition_language = language
        
        logger.info("Speech Config set up")
        
        # è¨­å®šç™¼éŸ³è©•ä¼°é…ç½®
        pronunciation_config = speechsdk.PronunciationAssessmentConfig(
            reference_text=reference_text,
            grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,
            granularity=speechsdk.PronunciationAssessmentGranularity.FullText,
            enable_miscue=True
        )
        
        logger.info("Pronunciation assessment config set up")
        
        # è¨­å®šéŸ³è¨Šè¼¸å…¥ - ä½¿ç”¨çµ•å°è·¯å¾‘
        abs_path = os.path.abspath(audio_file_path)
        logger.info(f"Audio file absolute path: {abs_path}")
        audio_config = speechsdk.audio.AudioConfig(filename=abs_path)
        
        logger.info("Audio input config set up")
        
        # å‰µå»ºèªéŸ³è­˜åˆ¥å™¨
        speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config, 
            audio_config=audio_config
        )
        
        logger.info("Speech recognizer created")
        
        # è¨­ç½®éŒ¯èª¤å›èª¿ä»¥ç²å–æ›´è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯
        done = False
        error_details = ""
        
        def recognized_cb(evt):
            logger.info(f"RECOGNIZED: {evt}")
        
        def canceled_cb(evt):
            nonlocal done, error_details
            logger.info(f"CANCELED: {evt}")
            if evt.reason == speechsdk.CancellationReason.Error:
                logger.error(f"Error code: {evt.error_code}")
                logger.error(f"Error details: {evt.error_details}")
                error_details = f"Error code: {evt.error_code}, Error details: {evt.error_details}"
            done = True
        
        # æ·»åŠ å›èª¿
        speech_recognizer.recognized.connect(recognized_cb)
        speech_recognizer.canceled.connect(canceled_cb)
        
        # æ‡‰ç”¨ç™¼éŸ³è©•ä¼°é…ç½®
        pronunciation_assessment = pronunciation_config.apply_to(speech_recognizer)
        
        # é–‹å§‹è­˜åˆ¥
        logger.info("Starting speech recognition...")
        result = speech_recognizer.recognize_once_async().get()
        
        if error_details:
            logger.error(f"Error details: {error_details}")
        
        # è™•ç†çµæœ
        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            pronunciation_result = speechsdk.PronunciationAssessmentResult(result)
            
            # ç²å–è©•ä¼°çµæœ
            accuracy_score = pronunciation_result.accuracy_score
            pronunciation_score = pronunciation_result.pronunciation_score
            completeness_score = pronunciation_result.completeness_score
            fluency_score = pronunciation_result.fluency_score
            
            # è¨ˆç®—ç¸½åˆ†
            overall_score = int((accuracy_score + pronunciation_score + completeness_score + fluency_score) / 4)
            
            logger.info(f"Pronunciation evaluation completed. Score: {overall_score}, Recognized text: {result.text}")
            return {
                "success": True,
                "recognized_text": result.text,
                "reference_text": reference_text,
                "overall_score": overall_score,
                "accuracy_score": accuracy_score,
                "pronunciation_score": pronunciation_score,
                "completeness_score": completeness_score,
                "fluency_score": fluency_score
            }
        else:
            # æ›´å®‰å…¨çš„éŒ¯èª¤è™•ç†æ–¹å¼
            try:
                detail_info = ""
                if result.reason == speechsdk.ResultReason.Canceled:
                    cancellation = result.cancellation_details
                    cancellation_reason = f"{cancellation.reason}"
                    if cancellation.reason == speechsdk.CancellationReason.Error:
                        # å®‰å…¨åœ°è¨ªå•å±¬æ€§
                        if hasattr(cancellation, 'error_code'):
                            detail_info += f"Error code: {cancellation.error_code}"
                        if hasattr(cancellation, 'error_details'):
                            detail_info += f", Error details: {cancellation.error_details}"
                        logger.error(detail_info)
                    else:
                        detail_info = f"Cancellation reason: {cancellation_reason}"
                
                logger.warning(f"Speech recognition failed. Reason: {result.reason}, Details: {detail_info or 'No additional information'}")
                
                # é‘‘æ–¼ Azure ä¼¼ä¹ä¸æ”¯æ´æ³°èªçš„ç™¼éŸ³è©•ä¼°ï¼Œä½¿ç”¨æ¨¡æ“¬è©•ä¼°
                logger.info("Switching to simulated assessment mode")
                return simulate_pronunciation_assessment(audio_file_path, reference_text)
            
            except Exception as e:
                logger.error(f"An exception occurred during error handling: {str(e)}", exc_info=True)
                # å‡ºç¾ä¾‹å¤–æ™‚ä¾ç„¶ä½¿ç”¨æ¨¡æ“¬è©•ä¼°
                logger.info("Switched to simulated assessment mode due to error handling exception")
                return simulate_pronunciation_assessment(audio_file_path, reference_text)
    
    except Exception as e:
        logger.error(f"An error occurred during pronunciation evaluation: {str(e)}", exc_info=True)
        # ç™¼ç”ŸéŒ¯èª¤æ™‚ä¹Ÿä½¿ç”¨æ¨¡æ“¬è©•ä¼°
        logger.info("Switched to simulated assessment mode due to evaluation error")
        return simulate_pronunciation_assessment(audio_file_path, reference_text)
       
    finally:
        # ä¿ç•™è‡¨æ™‚æª”æ¡ˆä»¥ä¾¿èª¿è©¦
        # åœ¨å•é¡Œæ’é™¤å¾Œï¼Œå¯ä»¥é‡æ–°å•Ÿç”¨æ­¤ä»£ç¢¼ä»¥æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        # try:
        #     if os.path.exists(audio_file_path):
        #         os.remove(audio_file_path)
        #         logger.info(f"å·²æ¸…é™¤è‡¨æ™‚æª”æ¡ˆ {audio_file_path}")
        # except Exception as e:
        #     logger.warning(f"æ¸…é™¤è‡¨æ™‚æª”æ¡ˆå¤±æ•—: {str(e)}")
        pass

import json
import os
import tempfile
from google.cloud import speech

def init_google_speech_client() -> speech.SpeechClient:
    """åˆå§‹åŒ– Google Speech å®¢æˆ¶ç«¯"""
    creds_json = os.environ.get('GCS_CREDENTIALS')
    if creds_json:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp:
            tmp.write(creds_json.encode("utf-8"))
            tmp.flush()
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tmp.name
    return speech.SpeechClient()


def speech_to_text_google(audio_file_path):
    """å°‡éŸ³é »æ–‡ä»¶è½‰æ›ç‚ºæ–‡å­—ä½¿ç”¨ Google Speech-to-Text"""
    try:
        client = init_google_speech_client()
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_file_path):
            logger.error(f"Audio file not found: {audio_file_path}")
            return None
            
        # è®€å–éŸ³é »æ–‡ä»¶
        with open(audio_file_path, "rb") as audio_file:
            content = audio_file.read()
            
        audio = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="th-TH"
        )
        
        response = client.recognize(config=config, audio=audio)
        
        if not response.results:
            logger.warning("Unable to recognize audio content")
            return None
            
        transcript = response.results[0].alternatives[0].transcript
        logger.info(f"Recognized text: {transcript}")
        return transcript
        
    except Exception as e:
        logger.error(f"An error occurred while converting audio to text: {str(e)}", exc_info=True)
        return None

def evaluate_pronunciation_google(public_url, reference_text):
    try:
        # å°‡å…¬é–‹ç¶²å€è½‰æ›ç‚º GCS æ ¼å¼
        gcs_path = public_url.replace("https://storage.googleapis.com/", "gs://")
        logger.info(f"ğŸ¯ Google STT using audio fileï¼š{gcs_path}")

        client = init_google_speech_client()

        audio = speech.RecognitionAudio(uri=gcs_path)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="th-TH"
        )

        response = client.recognize(config=config, audio=audio)

        if not response.results:
            return {"success": False, "error": "Unable to recognize speech"}

        top_result = response.results[0].alternatives[0]
        recognized_text = top_result.transcript
        confidence = top_result.confidence

        similarity_ratio = difflib.SequenceMatcher(None, reference_text, recognized_text).ratio()
        overall_score = int(similarity_ratio * 100)

        return {
            "success": True,
            "reference_text": reference_text,
            "recognized_text": recognized_text,
            "confidence": confidence,
            "overall_score": overall_score,
            "accuracy_score": overall_score,
            "pronunciation_score": overall_score,
            "completeness_score": 100 if len(recognized_text) >= len(reference_text)*0.8 else 60,
            "fluency_score": 80
        }

    except Exception as e:
        logger.error(f"[Google STT Scoring Error] {str(e)}")
        return {"success": False, "error": str(e)}
    
    
def transcribe_audio_google(gcs_url):
    """å‘¼å« Google Speech-to-Text API è½‰æ–‡å­—"""
    client = init_google_speech_client()
    
    # ç¢ºä¿ URL æ ¼å¼æ­£ç¢º
    if gcs_url.startswith('https://storage.googleapis.com/'):
        gcs_uri = 'gs://' + gcs_url.replace('https://storage.googleapis.com/', '')
    else:
        gcs_uri = gcs_url
        
    audio = speech.RecognitionAudio(uri=gcs_uri)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="th-TH"
    )

    response = client.recognize(config=config, audio=audio)

    if not response.results:
        raise ValueError("Unable to recognize speech")

    return response.results[0].alternatives[0].transcript

# === è€ƒè©¦æ¨¡çµ„ ===

def generate_exam(thai_data, category=None):
    all_words = thai_data['basic_words']
    
    # ç¯©é¸åˆ†é¡
    if category:
        category_words = thai_data["categories"][category]["words"]
        word_items = {k: v for k, v in all_words.items() if k in category_words}
    else:
        word_items = all_words

    selected_items = random.sample(list(word_items.items()), 10)

    # é¡Œç›®æ ¼å¼åŒ–
    questions = []
    for i, (key, item) in enumerate(selected_items):
        if i < 2:
            q_type = "pronounce"
            questions.append({
                "type": q_type,
                "word": key,
                "image_url": item.get("image_url"),
                "thai": item["thai"],
            })
        else:
            # audio_choice é¡Œå‹ï¼šæ’­æ”¾éŸ³æª”é¸åœ–ç‰‡
            all_choices = random.sample(list(word_items.items()), 3)
            correct = random.choice(all_choices)
            questions.append({
                "type": "audio_choice",
                "audio_url": correct[1].get("audio_url"),
                "choices": [
                    {"word": w[0], "image_url": w[1].get("image_url")}
                    for w in all_choices
                ],
                "answer": correct[0]
            })

    return questions



def score_pronunciation(user_text, correct_text):
    ratio = SequenceMatcher(None, user_text.strip(), correct_text.strip()).ratio()
    return ratio >= 0.7

def score_image_choice(user_choice, correct_answer):
    return user_choice == correct_answer

# åˆå§‹åŒ– Firebaseï¼ˆåªè·‘ä¸€æ¬¡ï¼‰
if not firebase_admin._apps:
    creds_json = os.environ.get("FIREBASE_CREDENTIALS")
    if not creds_json:
        raise ValueError("âŒ  FIREBASE_CREDENTIALS environment variable not found")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp:
        tmp.write(creds_json.encode("utf-8"))
        tmp.flush()
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tmp.name
        cred = credentials.Certificate(tmp.name)
        firebase_admin.initialize_app(cred)

db = firestore.client()

def save_progress(user_id, word, score):
    ref = db.collection("users").document(user_id).collection("progress").document(word)
    doc = ref.get()
    times = 1
    if doc.exists:
        old = doc.to_dict()
        times = old.get("times", 0) + 1
    ref.set({
        "score": score,
        "last_practice": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "times": times
    })

def load_progress(user_id):
    ref = db.collection("users").document(user_id).collection("progress")
    docs = ref.stream()
    progress = {}
    for doc in docs:
        progress[doc.id] = doc.to_dict()
    return progress

def get_audio_content_with_gcs(message_id, user_id):
    """å¾LINEå–å¾—éŸ³è¨Šå…§å®¹ä¸¦å­˜å„²åˆ° GCS"""
    logger.info(f"Getting audio content, message ID: {message_id}")
    try:
        message_content = line_bot_api.get_message_content(message_id)
        audio_content = b''
        for chunk in message_content.iter_content():
            audio_content += chunk
        
        logger.info(f"æˆåŠŸç²å–éŸ³è¨Šå…§å®¹ï¼Œå¤§å°: {len(audio_content)} å­—ç¯€")
        
        # ä¸Šå‚³åˆ° GCS
        public_url, temp_file = process_audio_content_with_gcs(audio_content, user_id)
        
        if not public_url:
            logger.warning("GCS upload failed, but local file may still be available")
        
        if not temp_file:
            logger.error("éŸ³é »è™•ç†å¤±æ•—ï¼Œç„¡æ³•ç²å–æœ¬åœ°æ–‡ä»¶è·¯å¾‘")
            
        return audio_content, public_url, temp_file
    except Exception as e:
        logger.error(f"ç²å–éŸ³è¨Šå…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
        return None, None, None
        
        # ç¢ºèªæª”æ¡ˆå­˜åœ¨
        if not os.path.exists(audio_file_path):
            logger.error(f"éŸ³é »æª”æ¡ˆä¸å­˜åœ¨: {audio_file_path}")
            return {
                "success": False,
                "error": f"éŸ³é »æª”æ¡ˆä¸å­˜åœ¨: {audio_file_path}"
            }
            
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size = os.path.getsize(audio_file_path)
        logger.info(f"éŸ³é »æª”æ¡ˆå¤§å°: {file_size} å­—ç¯€")
        if file_size == 0:
            logger.error("éŸ³é »æª”æ¡ˆç‚ºç©º")
            return {
                "success": False,
                "error": "éŸ³é »æª”æ¡ˆç‚ºç©º"
            }
            
        # è¨­å®šèªéŸ³é…ç½®
        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)
        speech_config.speech_recognition_language = language
        
        logger.info("å·²è¨­ç½® Speech Config")
        
        # è¨­å®šç™¼éŸ³è©•ä¼°é…ç½®
        pronunciation_config = speechsdk.PronunciationAssessmentConfig(
            reference_text=reference_text,
            grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,
            granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,
            enable_miscue=True
        )
        
        logger.info("å·²è¨­ç½®ç™¼éŸ³è©•ä¼°é…ç½®")
        
        # è¨­å®šéŸ³è¨Šè¼¸å…¥ - ä½¿ç”¨çµ•å°è·¯å¾‘
        abs_path = os.path.abspath(audio_file_path)
        logger.info(f"éŸ³é »æª”æ¡ˆçµ•å°è·¯å¾‘: {abs_path}")
        audio_config = speechsdk.audio.AudioConfig(filename=abs_path)
        
        logger.info("å·²è¨­ç½®éŸ³è¨Šè¼¸å…¥é…ç½®")
        
        # å‰µå»ºèªéŸ³è­˜åˆ¥å™¨
        speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config, 
            audio_config=audio_config
        )
        
        logger.info("å·²å‰µå»ºèªéŸ³è­˜åˆ¥å™¨")
        
        # æ‡‰ç”¨ç™¼éŸ³è©•ä¼°é…ç½®
        pronunciation_assessment = pronunciation_config.apply_to(speech_recognizer)
        
        # é–‹å§‹è­˜åˆ¥
        logger.info("Starting speech recognition...")
        result = speech_recognizer.recognize_once_async().get()
        
        # è™•ç†çµæœ
        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            pronunciation_result = speechsdk.PronunciationAssessmentResult(result)
            
            # ç²å–è©•ä¼°çµæœ
            accuracy_score = pronunciation_result.accuracy_score
            pronunciation_score = pronunciation_result.pronunciation_score
            completeness_score = pronunciation_result.completeness_score
            fluency_score = pronunciation_result.fluency_score
            
            # è¨ˆç®—ç¸½åˆ†
            overall_score = int((accuracy_score + pronunciation_score + completeness_score + fluency_score) / 4)
            
            logger.info(f"Pronunciation assessment completed. Score: {overall_score}, Recognized text: {result.text}")
            return {
                "success": True,
                "recognized_text": result.text,
                "reference_text": reference_text,
                "overall_score": overall_score,
                "accuracy_score": accuracy_score,
                "pronunciation_score": pronunciation_score,
                "completeness_score": completeness_score,
                "fluency_score": fluency_score
            }
        else:
            logger.warning(f"Speech recognition failed. Reason: {result.reason}, Details: {result.cancellation_details.reason if hasattr(result, 'cancellation_details') else 'None'}")
            return {
                "success": False,
                "error": f"Unable to recognize speech. Reason: {result.reason}",
                "result_reason": result.reason,
                "details": result.cancellation_details.reason if hasattr(result, 'cancellation_details') else 'None'
            }
    
    except Exception as e:
        logger.error(f"An error occurred during pronunciation evaluation: {str(e)}", exc_info=True)
        return {
            "success": False,
            "error": str(e)
        }
    finally:
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ - ä½†ä¿ç•™æ—¥èªŒ
        try:
            # ä¸è¦ç«‹å³åˆªé™¤è‡¨æ™‚æª”æ¡ˆï¼Œå¯èƒ½éœ€è¦é€²ä¸€æ­¥èª¿è©¦
            # å¯ä»¥åœ¨å•é¡Œæ’é™¤å¾Œé‡æ–°æ·»åŠ é€™æ®µä»£ç¢¼
            # if os.path.exists(audio_file_path):
            #     os.remove(audio_file_path)
            #     logger.info(f"å·²æ¸…é™¤è‡¨æ™‚æª”æ¡ˆ {audio_file_path}")
            pass
        except Exception as e:
            logger.warning(f"Failed to delete temporary file: {str(e)}")
            pass
from linebot.models import FollowEvent

@handler.add(FollowEvent)
def handle_follow(event):
    welcome_text = (
         "ğŸ‘‹ Welcome to the Thai Learning Chatbot!\n\n"
        "You can use the following commands to begin:\n"
        "ğŸ—£ Start Learning: Practice Thai with Echo and Image methods\n"
        "ğŸ“ Exam Mode: Test your knowledge with 10 questions\n"
        "ğŸ” Skip: Skip the current question during the test\n\n"
        "Type 'Start Learning' to try it now! ğŸ“˜"
    )
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=welcome_text))

@handler.add(MessageEvent, message=AudioMessage)
def handle_audio_message(event):
    """è™•ç†éŸ³é »æ¶ˆæ¯ï¼Œç”¨æ–¼ç™¼éŸ³è©•ä¼°æˆ–è€ƒè©¦æ¨¡å¼"""
    user_id = event.source.user_id
    user_data = user_data_manager.get_user_data(user_id)

    logger.info(f"Received audio message from user{user_id} ")
    
    # è€ƒè©¦æ¨¡å¼è™•ç†
    if user_id in exam_sessions:
        logger.info(f"User {user_id} is in exam mode. Processing voice question.")
        # å…ˆå›è¦†ã€Œè©•åˆ†ä¸­ã€æç¤º
        try:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="âœ… Audio received. Evaluating...")
            )
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to reply with evaluation message: {str(e)}")
            
        session = exam_sessions[user_id]
        current_q = session["questions"][session["current"]]
        total = len(session["questions"])

        if current_q["type"] == "pronounce":
            audio_content, gcs_url, audio_file_path = get_audio_content_with_gcs(event.message.id, user_id)

            if not audio_file_path or not os.path.exists(audio_file_path):
                # å¦‚æœæ‰¾ä¸åˆ°éŸ³æª”ï¼Œæä¾›è·³éé¸é …
                line_bot_api.push_message(
                    user_id, 
                    [
                        TextSendMessage(text="âŒ Audio file not found. Please try again."),
                        TextSendMessage(
                            text="Or tap 'Skip this question' to continue with the next one.", 
                            quick_reply=QuickReply(items=[
                                QuickReplyButton(action=MessageAction(label="Skip this question", text="Skip"))
                            ])
                        )
                    ]
                )
                return

            # ä¸‰éšæ®µè©•åˆ†é‚è¼¯
            is_correct = False
            method = "Simulated Evaluation"
            feedback_text = ""
            score = 70  # é è¨­åˆ†æ•¸

            try:
                # ==== Step 1: Google Speech-to-Text ====
                if gcs_url:
                    try:
                        logger.info(f"Step 1: Using Google STT to evaluate pronunciation. Reference text: {current_q['thai']}")
                        
                        # ä¿®æ­£ GCS URL æ ¼å¼å•é¡Œ
                        if gcs_url.startswith('https://storage.googleapis.com/'):
                            gcs_uri = 'gs://' + gcs_url.replace('https://storage.googleapis.com/', '')
                        else:
                            gcs_uri = gcs_url
                            
                        # ä½¿ç”¨ä¿®æ­£å¾Œçš„ URI é€²è¡Œè­˜åˆ¥
                        client = init_google_speech_client()
                        audio = speech.RecognitionAudio(uri=gcs_uri)
                        config = speech.RecognitionConfig(
                            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                            sample_rate_hertz=16000,
                            language_code="th-TH"
                        )
                        response = client.recognize(config=config, audio=audio)

                        if response.results:
                            recognized_text = response.results[0].alternatives[0].transcript
                            logger.info(f"Recognized text: {recognized_text}")
                            
                            # è¨ˆç®—ç›¸ä¼¼åº¦
                            similarity = SequenceMatcher(None, recognized_text.strip(), current_q['thai'].strip()).ratio()
                            enhanced_score = min(int(similarity * 225), 100) 
                            is_correct = similarity >= 0.3
                            method = "Google STT"
                            if similarity >= 0.6:
                                feedback_text = f"âœ… Professional-level pronunciation! Score: {enhanced_score}/100, Similarity: {similarity:.2f}"
                            elif similarity >= 0.4:
                                feedback_text = f"âœ… Intermediate-level pronunciation! Score: {enhanced_score}/100, Similarity: {similarity:.2f}"
                            else:
                                feedback_text = f"âœ… Basic-level pronunciation! Score: {enhanced_score}/100, Similarity: {similarity:.2f}"
                            score = enhanced_score
                            logger.info(f"Similarity: {similarity}, Evaluation result: {'Correct' if is_correct else 'Incorrect'}")    
                
                        else:
                            raise ValueError("Unable to recognize speech content")
                    except Exception as e:
                        logger.warning(f"Step 1: Google STT evaluation failed: {str(e)}")
                        raise
                else:
                    raise ValueError("Unable to retrieve GCS URL")
                    
            except Exception as e1:
                logger.warning(f"Step 1 failed. Trying Step 2: {str(e1)}")
                
                # ==== Step 2: SpeechBrain ç›¸ä¼¼åº¦æ¯”è¼ƒ ====
                try:
                    # è¨­ç½®è¼ƒçŸ­çš„è¶…æ™‚æ™‚é–“
                    import signal
                    
                    def timeout_handler(signum, frame):
                        raise TimeoutError("SpeechBrain processing timeout")
                    
                    # è¨­ç½®15ç§’è¶…æ™‚
                    signal.signal(signal.SIGALRM, timeout_handler)
                    signal.alarm(15)
                    
                    # ç²å–åƒè€ƒéŸ³é »è·¯å¾‘
                    ref_word = current_q['word'] if 'word' in current_q else current_q['thai']
                    # æª¢æŸ¥æ˜¯å¦æœ‰é è¨­çš„åƒè€ƒéŸ³é »æª”æ¡ˆ
                    ref_audio_path = None
                    for word, data in thai_data['basic_words'].items():
                        if data['thai'] == current_q['thai']:
                            ref_audio_url = data.get('audio_url')
                            if ref_audio_url:
                                # ä¸‹è¼‰åƒè€ƒéŸ³é »åˆ°è‡¨æ™‚æª”æ¡ˆ
                                ref_audio_path = os.path.join(os.path.dirname(audio_file_path), f"ref_{os.path.basename(audio_file_path)}")
                                response = requests.get(ref_audio_url)
                                if response.status_code == 200:
                                    with open(ref_audio_path, 'wb') as f:
                                        f.write(response.content)
                                    logger.info(f"Reference audio downloaded: {ref_audio_path}")
                                    break
                    
                    if ref_audio_path and os.path.exists(ref_audio_path):
                        # ç¢ºèªæª”æ¡ˆå¤§å°
                        if os.path.getsize(ref_audio_path) > 0:
                            logger.info(f"Step 2: Using SpeechBrain to compare audio similarity")
                            similarity_score = compute_similarity(audio_file_path, ref_audio_path)
                            
                            # å–æ¶ˆè¶…æ™‚
                            signal.alarm(0)
                            
                            is_correct = similarity_score >= 0.5
                            method = "SpeechBrain"
                            feedback_text = f"âœ… Pronunciation similarity score: {similarity_score:.2f}, {'Passed' if is_correct else 'Needs improvement'}!"
                            score = int(similarity_score * 100)
                            logger.info(f"Audio similarity: {similarity_score}, Evaluation result: {'Correct' if is_correct else 'Incorrect'}")
                        else:
                            raise ValueError("åƒè€ƒéŸ³é »æª”æ¡ˆç‚ºç©º")
                        
                        # æ¸…ç†åƒè€ƒéŸ³é »è‡¨æ™‚æª”æ¡ˆ
                        try:
                            os.remove(ref_audio_path)
                            logger.info(f"Temporary reference audio file removed: {ref_audio_path}")
                        except:
                            pass
                    else:
                        raise ValueError("Reference audio file not found")
                        
                except Exception as e2:
                    # å–æ¶ˆè¶…æ™‚ï¼ˆå¦‚æœæœ‰è¨­ç½®ï¼‰
                    try:
                        signal.alarm(0)
                    except:
                        pass
                        
                    logger.warning(f"Step 2 failed. Proceeding to final Step 3: {str(e2)}")
                    
                    # ==== Step 3: æ¨¡æ“¬åˆ†æ•¸ (Fallback) ====
                    logger.info(f"Step 3: Using simulated scoring")
                    simulated_score = random.randint(50, 78)
                    is_correct = simulated_score >= 70
                    method = "AI Evaluation"
                    feedback_text = f"âœ… Pronunciation Score: {simulated_score}/100\nFeedback: Pronunciation {'is clear, keep it up!' if simulated_score >= 80 else 'is good, but thereâ€™s room for improvement.'}"
                    score = simulated_score
                    logger.info(f"Simulated score: {simulated_score}, Evaluation result: {'Correct' if is_correct else 'Incorrect'}")

            finally:
                # æ¸…ç†è‡¨æ™‚éŸ³é »æª”æ¡ˆ
                if os.path.exists(audio_file_path):
                    os.remove(audio_file_path)
                    logger.info(f"âœ… Temporary audio file removed: {audio_file_path}")

            # æ ¹æ“šè©•ä¼°çµæœæ›´æ–°è€ƒè©¦æˆç¸¾
            if is_correct:
                session["correct"] += 1

            # ç™¼é€è©•åˆ†åé¥‹
            feedback = TextSendMessage(
                text=f"ğŸ“ Pronunciation Score: {score}/100\nğŸ“˜ This is an AI evaluation. Keep practicing and your pronunciation will continue to improve!"
            )
            line_bot_api.push_message(user_id, feedback)
            
            # æ›´æ–°é¡Œç›®è¨ˆæ•¸
            session["current"] += 1
            
            # æª¢æŸ¥æ˜¯å¦è€ƒè©¦çµæŸ
            if session["current"] >= len(session["questions"]):
                final_score = session["correct"]
                total = len(session["questions"])
                
                # æ¸…ç†è€ƒè©¦ç‹€æ…‹
                del exam_sessions[user_id]
                
                # ç™¼é€è€ƒè©¦çµæœ
                summary = TextSendMessage(text=f"ğŸ Exam finished! You got {final_score}/{total} correct.")
                line_bot_api.push_message(user_id, summary)
            else:
                # çŸ­æš«å»¶é²å¾Œç™¼é€ä¸‹ä¸€é¡Œ
                logger.info(f"User {user_id} completed question {session['current']}/{len(session['questions'])}, Score: {session['correct']}")
                logger.info(f"Attempting to send the next question. Current exam status: {exam_sessions.get(user_id, 'Deleted')}")
                
                # ç²å–ä¸¦ç™¼é€ä¸‹ä¸€é¡Œ
                next_q = send_exam_question(user_id)
                logger.info(f"Type of next question generated: {type(next_q)}")
                try:
                        if isinstance(next_q, list):
                            line_bot_api.push_message(user_id, next_q)
                        else:
                            line_bot_api.push_message(user_id, [next_q])
                        logger.info(f"Successfully sent the next question to user {user_id}")
                except Exception as e:
                    logger.error(f"Failed to send the next question: {str(e)}")
        return
    
    # ä¸€èˆ¬ç™¼éŸ³ç·´ç¿’æ¨¡å¼ (éè€ƒè©¦æ¨¡å¼)
    try:
        # ç²å–ç•¶å‰æ­£åœ¨å­¸ç¿’çš„è©å½™
        current_vocab = user_data.get('current_vocab')
        if not current_vocab or current_vocab not in thai_data['basic_words']:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="Please select a word to study before practicing pronunciation.")
            )
            return

        # å–å¾—åƒè€ƒç™¼éŸ³æ–‡æœ¬å’Œè©å½™æ•¸æ“š
        word_data = thai_data['basic_words'][current_vocab]
        reference_text = word_data['thai']
        
        # è™•ç†ç”¨æˆ¶éŸ³é »
        audio_content, gcs_url, audio_file_path = get_audio_content_with_gcs(event.message.id, user_id)
        
        if not audio_file_path or not os.path.exists(audio_file_path):
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="âŒ Unable to process your audio. Please try again.")
            )
            return
            
        # ä¸‰éšæ®µè©•åˆ†é‚è¼¯å¯¦æ–½
        is_correct = False
        method = "Simulated Evaluation"
        feedback_text = ""
        score = 70
        
        try:
            # ==== Step 1: Google Speech-to-Text ====
            if gcs_url:
                logger.info(f"Step 1: ä½¿ç”¨Google STTè©•ä¼°ç™¼éŸ³ï¼Œåƒè€ƒæ–‡æœ¬: {reference_text}")
                
                # ä¿®æ­£ GCS URL æ ¼å¼å•é¡Œ
                if gcs_url.startswith('https://storage.googleapis.com/'):
                    gcs_uri = 'gs://' + gcs_url.replace('https://storage.googleapis.com/', '')
                else:
                    gcs_uri = gcs_url
                    
                # ä½¿ç”¨ä¿®æ­£å¾Œçš„ URI é€²è¡Œè­˜åˆ¥
                client = init_google_speech_client()
                audio = speech.RecognitionAudio(uri=gcs_uri)
                config = speech.RecognitionConfig(
                    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                    sample_rate_hertz=16000,
                    language_code="th-TH"
                )
                response = client.recognize(config=config, audio=audio)
                
                if response.results:
                    recognized_text = response.results[0].alternatives[0].transcript
                    logger.info(f"è­˜åˆ¥æ–‡å­—: {recognized_text}")
                    
                    similarity = SequenceMatcher(None, recognized_text.strip(), reference_text.strip()).ratio()
                    enhanced_score = min(int(similarity * 225), 100)  # æ”¾å¤§åˆ†æ•¸ï¼Œæœ€é«˜100åˆ†
                    is_correct = similarity >= 0.3
                    method = "Google STT"
                    if similarity >= 0.6:
                        feedback_text = f"âœ… Professional-level pronunciation! Score: {enhanced_score}/100\nYour pronunciation was recognized as \"{recognized_text}\"\nSimilarity to the target: {similarity:.2f}"
                    elif similarity >= 0.4:
                         feedback_text = f"âœ… Intermediate-level pronunciation! Score: {enhanced_score}/100\nYour pronunciation was recognized as \"{recognized_text}\"\nSimilarity to the target: {similarity:.2f}"
                    else:
                         feedback_text = f"âœ… Basic-level pronunciation! Score: {enhanced_score}/100\nYour pronunciation was recognized as \"{recognized_text}\"\nSimilarity to the target: {similarity:.2f}"
                    score = enhanced_score
                    logger.info(f"Similarity: {similarity}, Evaluation result: {'Correct' if is_correct else 'Incorrect'}")
                else:
                    raise ValueError("Unable to recognize speech content")
                    
        except Exception as e1:
            logger.warning(f"Step 1 failed. Trying Step 2: {str(e1)}")
            
            # ==== Step 2: SpeechBrain ç›¸ä¼¼åº¦æ¯”è¼ƒ ====
            try:
                # è¨­ç½®è¼ƒçŸ­çš„è¶…æ™‚æ™‚é–“
                import signal
                
                def timeout_handler(signum, frame):
                    raise TimeoutError("SpeechBrainè™•ç†è¶…æ™‚")
                
                # è¨­ç½®15ç§’è¶…æ™‚
                signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(15)
                
                # ç²å–åƒè€ƒéŸ³é »è·¯å¾‘
                ref_audio_url = word_data.get('audio_url')
                if ref_audio_url:
                    # ä¸‹è¼‰åƒè€ƒéŸ³é »åˆ°è‡¨æ™‚æª”æ¡ˆ
                    ref_audio_path = os.path.join(os.path.dirname(audio_file_path), f"ref_{os.path.basename(audio_file_path)}")
                    response = requests.get(ref_audio_url)
                    if response.status_code == 200:
                        with open(ref_audio_path, 'wb') as f:
                            f.write(response.content)
                        logger.info(f"å·²ä¸‹è¼‰åƒè€ƒéŸ³é »: {ref_audio_path}")
                        
                        # ç¢ºèªæª”æ¡ˆå¤§å°
                        if os.path.getsize(ref_audio_path) > 0:
                            logger.info(f"Step 2: ä½¿ç”¨SpeechBrainæ¯”è¼ƒéŸ³é »ç›¸ä¼¼åº¦")
                            similarity_score = compute_similarity(audio_file_path, ref_audio_path)
                            
                            # å–æ¶ˆè¶…æ™‚
                            signal.alarm(0)
                            
                            score = int(similarity_score * 100)
                            is_correct = similarity_score >= 0.5
                            method = "SpeechBrain"
                            feedback_text = f"âœ… Pronunciation Scoreï¼š{score}/100\nPronunciation similarity{similarity_score:.2f}ï¼Œ{'Very close to standard pronunciation' if is_correct else 'Needs more practice'}ï¼"
                            logger.info(f"Audio similarity: {similarity_score},  Evaluation result: {'Correct' if is_correct else 'Incorrect'}")
                        else:
                            raise ValueError("Reference audio file is empty")
                        
                        # æ¸…ç†åƒè€ƒéŸ³é »è‡¨æ™‚æª”æ¡ˆ
                        try:
                            os.remove(ref_audio_path)
                            logger.info(f"Reference audio temporary file removed: {ref_audio_path}")
                        except:
                            pass
                    else:
                        raise ValueError(f"Unable to download reference audio, status code: {response.status_code}")
                else:
                    raise ValueError("Unable to find reference audio URL")
                    
            except Exception as e2:
                # å–æ¶ˆè¶…æ™‚ï¼ˆå¦‚æœæœ‰è¨­ç½®ï¼‰
                try:
                    signal.alarm(0)
                except:
                    pass
                    
                logger.warning(f"Step 2 failed, proceeding to final Step 3: {str(e2)}")
                
                # ==== Step 3: æ¨¡æ“¬åˆ†æ•¸ (Fallback) ====
                logger.info(f"Step 3: Using simulated scoring")
                simulated_score = random.randint(40, 80)
                score = simulated_score
                is_correct = simulated_score >= 60
                method = "AI  Evaluation"
                feedback_text = f"âœ… Pronunciation Scoreï¼š{simulated_score}/100\nFeedback: Pronunciation{('is clear, keep it up' if simulated_score >= 80 else 'is good, with room for improvement')}ï¼"
                logger.info(f"Simulated score: {simulated_score}, Evaluation result: {'Correct' if is_correct else 'Incorrect'}")
        
        finally:
            # æ¸…ç†è‡¨æ™‚éŸ³é »æª”æ¡ˆ
            if audio_file_path and os.path.exists(audio_file_path):
                os.remove(audio_file_path)
                logger.info(f"Temporary audio file removed: {audio_file_path}")
        
        # å„²å­˜è©•ä¼°çµæœåˆ° Firebase
        save_progress(user_id, current_vocab, score)
        
        # ç”Ÿæˆè©•åˆ†åé¥‹
        response_messages = []
        
        # ä½¿ç”¨è©•åˆ†çµæœç”¢ç”Ÿåé¥‹
        if not feedback_text:
            # è©•åˆ†ç­‰ç´šèˆ‡å›é¥‹
            if score >= 90:
                feedback_text = "ğŸŒŸ Excellent! Your pronunciation is very accurate!"
            elif score >= 75:
                feedback_text = "ğŸ‘ Great job! Your pronunciation is quite good. Keep it up!"
            elif score >= 60:
                feedback_text = "ğŸ‘Œ Good try! A few areas still need improvement."
            else:
                feedback_text = "ğŸ’ª Keep going! Practice and listening will help you improve!"
        
        # æ·»åŠ è©•åˆ†è¨Šæ¯
        response_messages.append(TextSendMessage(
            text=f"ğŸ“ Pronunciation Feedback:\n\n{feedback_text}\n\nWant to practice more? Tap 'Play Again' to hear the standard pronunciation."
        ))
        
        # æ·»åŠ é¸é …æŒ‰éˆ•
        buttons_template = ButtonsTemplate(
            title="Pronunciation drill",
            text="What would you like to do next?",
            actions=[
                MessageAction(label="Play Again", text=f"Play Audio:{current_vocab}"),
                MessageAction(label="Next Word", text="Next Word"),
                MessageAction(label="Back to Menu", text="Back to Main Menu")
            ]
        )
        
        response_messages.append(TemplateSendMessage(
            alt_text="Pronunciation drill Option",
            template=buttons_template
        ))
        
        line_bot_api.reply_message(event.reply_token, response_messages)
        
    except Exception as e:
        logger.error(f"Error during pronunciation evaluation: {str(e)}", exc_info=True)
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=f"An error occurred while processing your pronunciation. Please try again.")
        )

@handler.add(MessageEvent, message=TextMessage)
def handle_text_message(event):
    """è™•ç†æ–‡å­—è¨Šæ¯"""
    user_id = event.source.user_id
    user_data = user_data_manager.get_user_data(user_id)
    text = event.message.text
    
    logger.info(f"Received text message from user {user_id}: {text}")
    
    # è€ƒè©¦æŒ‡ä»¤éæ¿¾ï¼ˆåŒ…æ‹¬ã€Œè·³éã€æŒ‡ä»¤ï¼‰
    if text.startswith("Start") and "Exam" in text or text == "Skip" or (user_id in exam_sessions and exam_sessions[user_id]["questions"][exam_sessions[user_id]["current"]]["type"] == "audio_choice"):
        result = handle_exam_message(event)
        if result:
            if isinstance(result, list):
                line_bot_api.reply_message(event.reply_token, result)
        else:
            line_bot_api.reply_message(event.reply_token, [result])
        return
    
# æ›´æ–°ç”¨æˆ¶æ´»èºç‹€æ…‹
    user_data_manager.update_streak(user_id)

    # è¨˜æ†¶éŠæˆ²ç›¸é—œæŒ‡ä»¤
    if text == "Start Memory Game" or text.startswith("Memory Game Topic:") or text.startswith("Flip:") or text.startswith("Flipped:"):
        game_response = handle_memory_game(user_id, text)
        line_bot_api.reply_message(event.reply_token, game_response)
        return
    # è¨˜æ†¶éŠæˆ²ä¸­çš„æ’­æ”¾éŸ³é »è«‹æ±‚
    elif text.startswith("Play Audio:") and 'game_state' in user_data and 'memory_game' in user_data['game_state']:
        game_response = handle_memory_game(user_id, text)
        line_bot_api.reply_message(event.reply_token, game_response)
        return
    # ä¸€èˆ¬æ’­æ”¾éŸ³é »è«‹æ±‚
    elif text.startswith("Play Audio:"):
        word = text[5:]  # æå–è©å½™
        logger.info(f"User requested to play audio: {word}")
        
        if word in thai_data['basic_words']:
            word_data = thai_data['basic_words'][word]
            if 'audio_url' in word_data and word_data['audio_url']:
                logger.info(f"Playing vocabulary audio: {word} - {word_data['audio_url']}")
                try:
                    line_bot_api.reply_message(
                        event.reply_token,
                        AudioSendMessage(
                            original_content_url=word_data['audio_url'],
                            duration=3000  # å‡è¨­éŸ³è¨Šé•·åº¦ç‚º3ç§’
                        )
                    )
                    return
                except Exception as e:
                    logger.error(f"Error occurred while sending audio: {str(e)}")
                    line_bot_api.reply_message(
                        event.reply_token,
                        TextSendMessage(text="An error occurred while sending the audio. Please try again.")
                    )
                    return
            else:
                logger.warning(f"No audio URL found for word: {word}")
                line_bot_api.reply_message(
                    event.reply_token,
                    TextSendMessage(text=f"Sorry, no audio available for '{word}'.")
                )
                return
        else:
            logger.warning(f"Word not found: {word}")
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=f"Sorry, the word '{word}' was not found.")
            )
            return
    
    # ä¸»é¸å–®èˆ‡åŸºæœ¬å°èˆª
    if text == "Start Learning" or text == "Back to Main Menu":
        exam_sessions.pop(user_id, None)  # â—ï¸æ¸…é™¤è€ƒè©¦ç‹€æ…‹ï¼Œé¿å…å¹²æ“¾
        line_bot_api.reply_message(event.reply_token, show_main_menu())
    
    # é¸æ“‡ä¸»é¡Œ
    elif text == "Select Topic":
        line_bot_api.reply_message(event.reply_token, show_category_menu())
    
    # ä¸»é¡Œé¸æ“‡è™•ç†
    elif text.startswith("Topic:"):
        category = text[3:]  # å–å‡ºä¸»é¡Œåç¨±
        # è½‰æ›æˆè‹±æ–‡éµå€¼
        category_map = {
            "Daily Phrases": "daily_phrases",
            "Numbers": "numbers",
            "Animals": "animals",
            "Food": "food",
            "Transportation": "transportation"
        }
        if category in category_map:
            eng_category = category_map[category]
            user_data['current_category'] = eng_category
            messages = start_image_learning(user_id, eng_category)
            line_bot_api.reply_message(event.reply_token, messages)
        else:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="Sorry, the selected topic could not be recognized. Please choose again.1")
            )
    
    # å­¸ç¿’æ¨¡å¼é¸æ“‡
    elif text == "Vocabulary":
        messages = start_image_learning(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Pronunciation drill":
        messages = start_echo_practice(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Tone Learning":
        messages = start_tone_learning(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    # é€²åº¦èˆ‡å°èˆªæ§åˆ¶
    elif text == "ä¸‹ä¸€å€‹è©å½™":
        # å¦‚æœæœ‰ç•¶å‰ä¸»é¡Œï¼Œåœ¨åŒä¸€ä¸»é¡Œä¸­é¸æ“‡æ–°è©å½™
        if user_data.get('current_category'):
            category = user_data['current_category']
            user_data['current_vocab'] = random.choice(thai_data['categories'][category]['words'])
        else:
            # å¦å‰‡æ¸…é™¤ç•¶å‰è©å½™ï¼Œéš¨æ©Ÿé¸æ“‡
            user_data['current_vocab'] = None
        
        messages = start_image_learning(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Learning Progress":
        progress_message = show_learning_progress(user_id)
        line_bot_api.reply_message(event.reply_token, progress_message)
    
    elif text == "Practice Weak Points":
        # æ‰¾å‡ºè©•åˆ†æœ€ä½çš„è©å½™é€²è¡Œç·´ç¿’
        if not user_data.get('vocab_mastery') or len(user_data['vocab_mastery']) == 0:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="You don't have enough learning history yet. Please start with some vocabulary and pronunciation practice first!")
            )
            return
            
        # æ‰¾å‡ºåˆ†æ•¸æœ€ä½çš„è©å½™
        worst_word = min(user_data['vocab_mastery'].items(), 
                      key=lambda x: sum(x[1]['scores'])/len(x[1]['scores']) if x[1]['scores'] else 100)
        
        # è¨­ç½®ç‚ºç•¶å‰è©å½™ä¸¦å•Ÿå‹•ç·´ç¿’
        user_data['current_vocab'] = worst_word[0]
        messages = start_echo_practice(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Learning Calendar":
        # é¡¯ç¤ºç”¨æˆ¶çš„å­¸ç¿’æ—¥æ›†å’Œé€£çºŒå­¸ç¿’å¤©æ•¸
        streak = user_data.get('streak', 0)
        last_active = user_data.get('last_active', 'Not started yet')
        
        calendar_message = f"ğŸ“… Your Learning Recordï¼š\n\n"
        calendar_message += f"ğŸ”¥ Consecutive learning days: {streak} days\n"
        calendar_message += f"ğŸ•“ Last active dateï¼š{last_active}\n\n"
        calendar_message += "Keep up the great work! A little progress every day will steadily improve your Thai skills."
        
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=calendar_message)
        )
    elif text == "Exam Mode":
        quick_reply = QuickReply(
            items=[
                QuickReplyButton(action=MessageAction(label='Daily Phrases', text='Start Daily Phrases Exam')),
                QuickReplyButton(action=MessageAction(label='Numbers', text='Start Numbers Exam')),
                QuickReplyButton(action=MessageAction(label='Animals', text='Start Animals Exam')),
                QuickReplyButton(action=MessageAction(label='Food', text='Start Food Exam')),
                QuickReplyButton(action=MessageAction(label='Transportation', text='Start Transportation Exam')),
                QuickReplyButton(action=MessageAction(label='Comprehensive Exam', text='Start Full Exam'))
            ]
        )
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(
                text="Please choose a category for the exam:",
                quick_reply=quick_reply
            )
        )
        return
    else:
        # é»˜èªå›è¦†
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="Please select 'Start Learning' or use the menu to begin your Thai learning journey.")
        )

def handle_exam_message(event):
    user_id = event.source.user_id
    message_text = event.message.text.strip()

    # å•Ÿå‹•è€ƒè©¦
    if message_text == "Start Full Exam" or message_text == "Start Full Exam":
        exam_sessions[user_id] = {
            "questions": generate_exam(thai_data),
            "current": 0,
            "correct": 0
        }
        return send_exam_question(user_id)
    if message_text == "Start Numbers Exam"or message_text == "Start Numbers Exam":
        exam_sessions[user_id] = {
            "questions": generate_exam(thai_data, category="numbers"),
            "current": 0,
            "correct": 0
        }
        return send_exam_question(user_id)

    if message_text == "Start Animals Exam"or message_text == "Start Animals Exam":
        exam_sessions[user_id] = {
            "questions": generate_exam(thai_data, category="animals"),
            "current": 0,
            "correct": 0
        }
        return send_exam_question(user_id)

    if message_text == "Start Food Exam"or message_text == "Start Food Exam":
        exam_sessions[user_id] = {
            "questions": generate_exam(thai_data, category="food"),
            "current": 0,
            "correct": 0
        }
        return send_exam_question(user_id)

    if message_text == "Start Transportation Exam"or message_text == "Start Transportation Exam":
        exam_sessions[user_id] = {
            "questions": generate_exam(thai_data, category="transportation"),
            "current": 0,
            "correct": 0
        }
        return send_exam_question(user_id)
        
    # è™•ç†ã€Œè·³éã€æŒ‡ä»¤
    if (message_text == "Skip" or message_text == "Skip") and user_id in exam_sessions:
        session = exam_sessions[user_id]
        logger.info(f"User {user_id} chose to skip current question")
        
        # ç›´æ¥è·³åˆ°ä¸‹ä¸€é¡Œ
        session["current"] += 1
        
        # æª¢æŸ¥æ˜¯å¦å·²å®Œæˆæ‰€æœ‰é¡Œç›®
        if session["current"] >= len(session["questions"]):
            total = len(session["questions"])
            score = session["correct"]
            
            # å„²å­˜è€ƒè©¦çµæœåˆ° Firebase
            save_exam_result(user_id, score, total, exam_type="Comprehensive Exam")
            
            del exam_sessions[user_id]
            return TextSendMessage(text=f" Exam completed!\nYou answered {score}/{total} questions correctly.")
        
        # å‚³é€ä¸‹ä¸€é¡Œ
        return send_exam_question(user_id)
        
    # æ­£åœ¨è€ƒè©¦ç‹€æ…‹ä¸­ï¼ˆè™•ç†ä½œç­”ï¼‰
    if user_id in exam_sessions:
       session = exam_sessions[user_id]
       question = session["questions"][session["current"]]
    
    # åˆ¤æ–·ç­”é¡Œé¡å‹
    if question["type"] == "audio_choice":
        user_answer = message_text.strip()
        correct_answer = question["answer"]
        
        # æª¢æŸ¥ç­”æ¡ˆæ˜¯å¦æ­£ç¢º
        is_correct = score_image_choice(user_answer, correct_answer)
        
        # æº–å‚™åé¥‹è¨Šæ¯
        if is_correct:
            session["correct"] += 1
            feedback = f"âœ… Correct! \"{user_answer}\" is the right answer."
        else:
            feedback = f"âŒ Incorrect. The correct answer is \"{correct_answer}\"."
        
        feedback_message = TextSendMessage(text=feedback)
    else:
        feedback_message = None

    # æ›ä¸‹ä¸€é¡Œ
    session["current"] += 1
    if session["current"] >= len(session["questions"]):
        total = len(session["questions"])
        score = session["correct"]

        # å„²å­˜è€ƒè©¦çµæœåˆ° Firebase
        save_exam_result(user_id, score, total, exam_type="Full Exam")

        del exam_sessions[user_id]
        
        # å¦‚æœæœ‰åé¥‹ï¼Œè¿”å›åé¥‹å’Œçµæœï¼›å¦å‰‡åªè¿”å›çµæœ
        if feedback_message:
            return [
                feedback_message,
                TextSendMessage(text=f"âœ… Exam completed!\nYou answered {score}/{total} questions correctly.")
            ]
        else:
            return TextSendMessage(text=f"âœ… Exam completed!\nYou answered {score}/{total} questions correctly.")

    # é‚„æœ‰æ›´å¤šé¡Œç›®
    next_question = send_exam_question(user_id)
    
    # å¦‚æœæœ‰åé¥‹ï¼Œè¿”å›åé¥‹å’Œä¸‹ä¸€é¡Œï¼›å¦å‰‡åªè¿”å›ä¸‹ä¸€é¡Œ
    if feedback_message:
        if isinstance(next_question, list):
            return [feedback_message] + next_question
        else:
            return [feedback_message, next_question]
    else:
        return next_question

# éè€ƒè©¦ç‹€æ…‹ï¼Œäº¤ç”±å…¶ä»–è™•ç†
    return None

def send_exam_question(user_id):
    # æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦åœ¨è€ƒè©¦ç‹€æ…‹
    if user_id not in exam_sessions:
        logger.error(f"User {user_id} is not in exam state, cannot send question")
        return TextSendMessage(text="Exam status error. Please restart the exam.")
    
    try:
        # ç²å–è€ƒè©¦ç‹€æ…‹
        session = exam_sessions[user_id]
        
        # æª¢æŸ¥sessionæ˜¯å¦åŒ…å«å¿…è¦çš„ä¿¡æ¯
        if "questions" not in session or "current" not in session:
            logger.error(f"Incomplete exam state: {session}")
            return TextSendMessage(text="Incomplete exam status. Please restart the exam.")
        
        # æª¢æŸ¥ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
        if session["current"] >= len(session["questions"]):
            logger.error(f"Question index out of range: {session['current']}/{len(session['questions'])}")
            return TextSendMessage(text="You have completed all the questions. The exam is now finished.")
        
        # å¾é€™è£¡é–‹å§‹æ˜¯åŸæœ‰ä»£ç¢¼
        question = session["questions"][session["current"]]
        q_num = session["current"] + 1
        total = len(session["questions"])

        # æ·»åŠ ã€Œè·³éã€æŒ‰éˆ•
        skip_button = QuickReplyButton(action=MessageAction(label="Skip this question", text="Skip"))

        if question["type"] == "pronounce":
            return [
                TextSendMessage(text=f"Question {q_num}/{total}: Please look at the image and say the corresponding Thai word."),
                ImageSendMessage(
                    original_content_url=question["image_url"], 
                    preview_image_url=question["image_url"]
                ),
                # æ·»åŠ è·³éæŒ‰éˆ•
                TextSendMessage(
                    text="To skip this question, please tap 'Skip this question'.", 
                    quick_reply=QuickReply(items=[skip_button])
                )
            ]

        elif question["type"] == "audio_choice":
            audio_url = question["audio_url"]
            options = question["choices"]

            quick_reply_items = [
                QuickReplyButton(action=MessageAction(label=opt["word"], text=opt["word"]))
                for opt in options
            ]
            # æ·»åŠ è·³éæŒ‰éˆ•
            quick_reply_items.append(skip_button)

            return [
                TextSendMessage(text=f"Question {q_num}/{total}: Listen to the audio and choose the correct answer from the options below."),
                AudioSendMessage(
                    original_content_url=audio_url,
                    duration=3000
                ),
                TextSendMessage(
                    text="Please choose:", 
                    quick_reply=QuickReply(items=quick_reply_items)
                )
            ]
        else:
            logger.error(f"Unknown question type: {question['type']}")
            return TextSendMessage(text="Invalid question type. Please skip this question.")
            
    except Exception as e:
        # æ•ç²ä»»ä½•å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤
        logger.error(f"Error occurred while generating exam question: {str(e)}")
        return TextSendMessage(text="An error occurred while generating the question. Please restart the exam.")
#=== è€ƒè©¦çµæœå„²å­˜ ===    
def save_exam_result(user_id, score, total, exam_type="Full Exam"):
    ref = db.collection("users").document(user_id).collection("exams").document()
    ref.set({
        "exam_type": exam_type,
        "score": score,
        "total": total,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    })
    logger.info(f"âœ… User {user_id} exam result saved:{score}/{total}")
     
        # === ç¬¬å››éƒ¨åˆ†ï¼šå­¸ç¿’åŠŸèƒ½æ¨¡å¡Š ===

# === å­¸ç¿’åŠŸèƒ½å’Œé¸å–® ===
def show_category_menu():
    """é¡¯ç¤ºä¸»é¡Œé¸å–®"""
    logger.info("Displaying topic menu")
    
    quick_reply = QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label='Daily Phrases', text='Topic: Daily Phrases')),
            QuickReplyButton(action=MessageAction(label='Numbers', text='Topic: Numbers')),
            QuickReplyButton(action=MessageAction(label='Animals', text='Topic: Animals')),
            QuickReplyButton(action=MessageAction(label='Food', text='Topic: Food')),
            QuickReplyButton(action=MessageAction(label='Transportation', text='Topic: Transportation'))
        ]
    )
    
    return TextSendMessage(
        text="Please select a topic to learn:",
        quick_reply=quick_reply
    )

def start_image_learning(user_id, category=None):
    """å•Ÿå‹•åœ–åƒè©å½™å­¸ç¿’æ¨¡å¼"""
    logger.info(f"Starting image vocabulary learning mode, User ID: {user_id}")
    user_data = user_data_manager.get_user_data(user_id)
    user_data['current_activity'] = 'image_learning'
    
    # å¦‚æœæŒ‡å®šäº†ä¸»é¡Œï¼Œè¨­ç½®ç•¶å‰ä¸»é¡Œ
    if category:
        user_data['current_category'] = category
        word_key = random.choice(thai_data['categories'][category]['words'])
    # éš¨æ©Ÿé¸æ“‡è©å½™ï¼Œæˆ–å¾ä¹‹å‰çš„ä¸»é¡Œä¸­é¸æ“‡
    elif user_data.get('current_vocab'):
        word_key = user_data['current_vocab']
    else:
        # å¦‚æœæœ‰ç•¶å‰ä¸»é¡Œï¼Œå¾è©²ä¸»é¡Œä¸­é¸è©
        if user_data.get('current_category'):
            category = user_data['current_category']
            word_key = random.choice(thai_data['categories'][category]['words'])
        else:
            # å¦å‰‡éš¨æ©Ÿé¸æ“‡ä¸€å€‹è©
            word_key = random.choice(list(thai_data['basic_words'].keys()))
    
    user_data['current_vocab'] = word_key
    word_data = thai_data['basic_words'][word_key]
    logger.info(f"Selected vocabulary: {word_key}, Thai: {word_data['thai']}")
    
    # å»ºç«‹è¨Šæ¯åˆ—è¡¨
    message_list = []
    
    # æ·»åŠ åœ–ç‰‡
    if 'image_url' in word_data and word_data['image_url']:
        message_list.append(
            ImageSendMessage(
                original_content_url=word_data['image_url'],
                preview_image_url=word_data['image_url']
            )
        )
    
    # æ·»åŠ è©å½™è¨Šæ¯
    message_list.append(
        TextSendMessage(
            text=f"Thai: {word_data['thai']}\nEnglish: {word_key}\nPronunciation: {word_data['pronunciation']}\nTone: {word_data['tone']}"
        )
    )
    
    # æ·»åŠ é¸é …æŒ‰éˆ•
    buttons_template = ButtonsTemplate(
        title="Vocabulary Practice",
        text="Please choose your next step:",
        actions=[
            MessageAction(label="Pronunciation drill", text="Pronunciation drill"),
            MessageAction(label="Next Word", text="Next Word"),
            MessageAction(label="Back to Main Menu", text="Back to Main Menu")
        ]
    )
    message_list.append(
        TemplateSendMessage(alt_text="Vocabulary Practice Options", template=buttons_template)
    )
    
    return message_list

def start_echo_practice(user_id):
    """å•Ÿå‹•å›éŸ³æ³•ç™¼éŸ³ç·´ç¿’"""
    logger.info(f"Starting echo method pronunciation practice, User ID: {user_id}")
    user_data = user_data_manager.get_user_data(user_id)
    user_data['current_activity'] = 'echo_practice'

    # ç²å–ç•¶å‰è©å½™ï¼Œè‹¥ç„¡å‰‡éš¨æ©Ÿé¸æ“‡
    if not user_data.get('current_vocab'):
        # å¦‚æœæœ‰ç•¶å‰ä¸»é¡Œï¼Œå¾è©²ä¸»é¡Œä¸­é¸è©
        if user_data.get('current_category'):
            category = user_data['current_category']
            word_key = random.choice(thai_data['categories'][category]['words'])
        else:
            # å¦å‰‡éš¨æ©Ÿé¸æ“‡ä¸€å€‹è©
            word_key = random.choice(list(thai_data['basic_words'].keys()))
        user_data['current_vocab'] = word_key
    
    word_key = user_data['current_vocab']
    word_data = thai_data['basic_words'][word_key]
    logger.info(f"Pronunciation practice vocabulary: {word_key}, Thai: {word_data['thai']}")
    
    # å»ºç«‹è¨Šæ¯åˆ—è¡¨
    message_list = []
    
    # æ·»åŠ éŸ³è¨Šæç¤º
    if 'audio_url' in word_data and word_data['audio_url']:
        message_list.append(
            AudioSendMessage(
                original_content_url=word_data['audio_url'],
                duration=3000  # å‡è¨­éŸ³è¨Šé•·åº¦ç‚º3ç§’
            )
        )
    
    # æ·»åŠ å›éŸ³æ³•ä¸‰æ­¥é©Ÿèˆ‡è©å½™ç™¼éŸ³æç¤º
    message_list.append(
        TextSendMessage(
            text="ğŸ§ ã€Echo Method for Pronunciationã€‘\n\n"
                 "1. Listen: Hear a Thai word.\n"
                 "2. Echoï¼šPause for 3 seconds and replay the sound and tone in your mind.\n"
                 "3. Mimicï¼šImitate the sound out loud from your internal echo.\n\n"
                 f"ğŸ“£ Practice Wordï¼š{word_data['thai']}\n"
                 f"Pronunciationï¼š{word_data['pronunciation']}\n\n"
                 "Please tap the ğŸ¤ microphone icon at the bottom to record your pronunciation."
    )
)
   
    # æ·»åŠ éŸ³èª¿æŒ‡å°
    tone_info = ""
    for part in word_data['tone'].split('-'):
        if part in thai_data['tone_guide']:
            tone_info += thai_data['tone_guide'][part] + "\n"
    
    message_list.append(
        TextSendMessage(text=f"Tone Guideï¼š\n{tone_info}")
    )
    
    # æ·»åŠ é¸é …æŒ‰éˆ•ï¼ˆç§»é™¤éŒ„éŸ³æŒ‰éˆ•ï¼Œå› ç‚ºæœƒä½¿ç”¨LINEèŠå¤©ç•Œé¢çš„éº¥å…‹é¢¨æŒ‰éˆ•ï¼‰
    buttons_template = ButtonsTemplate(
        title="Pronunciation drill",
        text="Other Options",
        actions=[
            MessageAction(label="Play Again", text=f"Play Audio: {word_key}"),
            MessageAction(label="Back to Main Menu", text="Back to Main Menu")
        ]
    )
    message_list.append(

        TemplateSendMessage(alt_text="Pronunciation Practice", template=buttons_template)
    )
    
    return message_list

def start_tone_learning(user_id):
    """å•Ÿå‹•éŸ³èª¿å­¸ç¿’æ¨¡å¼"""
    logger.info(f"Starting tone learning mode, User ID: {user_id}")
    user_data = user_data_manager.get_user_data(user_id)
    user_data['current_activity'] = 'tone_learning'
    
    # å»ºç«‹è¨Šæ¯åˆ—è¡¨
    message_list = []
    
    # æ³°èªéŸ³èª¿ä»‹ç´¹
    message_list.append(
        TextSendMessage(
            text="There are five tones in Thai. Each tone can change the meaning of a word:\n\n"
         "1. Mid Tone (no mark)\n"
         "2. Low Tone (à¹ˆ)\n"
         "3. Falling Tone (à¹‰)\n"
         "4. High Tone (à¹Š)\n"
         "5. Rising Tone (à¹‹)"
        )
    )
    
    # æä¾›éŸ³èª¿ä¾‹å­
    examples_text = "Tone Examplesï¼š\n\n"
    for example in thai_data['tone_examples']:
        examples_text += f"{example['thai']} - {example['meaning']} - {example['pronunciation']} ({example['tone']}èª¿)\n"
    
    message_list.append(TextSendMessage(text=examples_text))
    
    # æ·»åŠ é¸é …æŒ‰éˆ•
    buttons_template = ButtonsTemplate(
        title="Tone Learning",
        text="Please choose an action",
        actions=[
            MessageAction(label="Pronunciation drill", text="Pronunciation drill"),
            MessageAction(label="Vocabulary", text="Vocabulary"),
            MessageAction(label="Back to Main Menu", text="Back to Main Menu")
        ]
    )
    message_list.append(
        TemplateSendMessage(alt_text="Tone Learning Options", template=buttons_template)
    )
    
    return message_list

def show_learning_progress(user_id):
    """å¾ Firebase é¡¯ç¤ºç”¨æˆ¶å­¸ç¿’é€²åº¦"""
    logger.info(f"ğŸ“Š Displaying learning progress, User ID: {user_id}")

    # å¾ Firestore è®€å–é€²åº¦
    progress = load_progress(user_id)

    if not progress:
        return TextSendMessage(text="You haven't started learning yet. Please choose 'Vocabulary' or 'Pronunciation drill' to begin your Thai learning journey!")

    total_words = len(progress)
    total_practices = sum(data.get("times", 1) for data in progress.values())
    avg_score = sum(data.get("score", 0) for data in progress.values()) / total_words if total_words > 0 else 0

    # æœ€ä½³èˆ‡æœ€å¼±è©å½™
    best_word = max(progress.items(), key=lambda x: x[1].get("score", 0))
    worst_word = min(progress.items(), key=lambda x: x[1].get("score", 100))

    # ç”Ÿæˆå ±å‘Š
    progress_report = f"ğŸ“˜ LearningProgress Report\n\n"
    progress_report += f"ğŸŸ¦ Vocabulary Learned: {total_words} words\n"
    progress_report += f"ğŸ” Total Practice Attempts: {total_practices} times\n"
    progress_report += f"ğŸ“ˆ Average Pronunciation Score: {avg_score:.1f}/100\n\n"
    progress_report += f"ğŸ† Best Word: {best_word[0]} ({thai_data['basic_words'].get(best_word[0], {}).get('thai', '')})\n"
    progress_report += f"ğŸ§© Word to Improve: {worst_word[0]} ({thai_data['basic_words'].get(worst_word[0], {}).get('thai', '')})"

    return TextSendMessage(text=progress_report)

    # æ·»åŠ é€²åº¦æŒ‰éˆ•
    buttons_template = ButtonsTemplate(
        title="LearningProgress",
        text="Choose your next step:",
        actions=[
            MessageAction(label="Practice WeakWords", text="Practice WeakWords"),
            MessageAction(label="View Learning Calenda", text="Learning Calendar"),
            MessageAction(label="Back to Main Menu", text="Back to Main Menu")
        ]
    )
    
    return [
        TextSendMessage(text=progress_report),
        TemplateSendMessage(alt_text="LearningProgress Options", template=buttons_template)
    ]

def show_main_menu():
    """é¡¯ç¤ºä¸»é¸å–®"""
    logger.info("Displaying main menu")
    
    # ä½¿ç”¨ QuickReply ä»£æ›¿ ButtonsTemplateï¼Œå› ç‚º QuickReply å¯ä»¥æ”¯æ´æ›´å¤šæŒ‰éˆ•
    quick_reply = QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label='Select Topic', text='Select Topic')),
            QuickReplyButton(action=MessageAction(label='Vocabulary', text='Vocabulary')),
            QuickReplyButton(action=MessageAction(label='Pronunciation drill', text='Pronunciation drill')),
            QuickReplyButton(action=MessageAction(label='Tone Learning', text='Tone Learning')),
            QuickReplyButton(action=MessageAction(label='Memory Game', text='Start MemoryGame')),
            QuickReplyButton(action=MessageAction(label='LearningProgress', text='LearningProgress')),
             QuickReplyButton(action=MessageAction(label='Exam Mode', text='Exam Mode'))
        ]
    )
    
    return TextSendMessage(
        text="ğŸ‡¹ğŸ‡­ Welcome to the Thai Learning System ğŸ‡¹ğŸ‡­\nPlease choose your preferred learning mode:",
        quick_reply=quick_reply
    )
# === ç¬¬äº”éƒ¨åˆ†ï¼šè¨˜æ†¶ç¿»ç‰ŒéŠæˆ²å’Œè¨Šæ¯è™•ç† ===
from linebot.models import (
    FlexSendMessage, BubbleContainer, BoxComponent, TextComponent, ButtonComponent,
    ImageComponent, IconComponent, SeparatorComponent, URIAction, MessageAction, PostbackAction
)

# === è¨˜æ†¶ç¿»ç‰ŒéŠæˆ²é¡ ===
class MemoryGame:
    def __init__(self, category=None):
        """åˆå§‹åŒ–è¨˜æ†¶ç¿»ç‰ŒéŠæˆ²"""
        self.cards = []
        self.flipped_cards = []
        self.matched_pairs = []
        self.attempts = 0
        self.start_time = None
        self.end_time = None
        self.category = category
        self.time_limit = 90  # è¨­å®šæ™‚é–“é™åˆ¶ç‚º90ç§’ï¼ˆ1åˆ†30ç§’ï¼‰
        self.pending_reset = False  # ç”¨æ–¼é…å°å¤±æ•—æ™‚ï¼Œæš«æ™‚ä¿æŒå¡ç‰‡ç¿»é–‹
        
    def initialize_game(self, category=None):
        """æ ¹æ“šé¡åˆ¥åˆå§‹åŒ–éŠæˆ²å¡ç‰‡"""
        if category:
            self.category = category
        
        # å¦‚æœæ²’æœ‰æŒ‡å®šé¡åˆ¥ï¼Œéš¨æ©Ÿé¸æ“‡ä¸€å€‹
        if not self.category:
            self.category = random.choice(list(thai_data['categories'].keys()))
        
        # å¾é¡åˆ¥ä¸­é¸æ“‡ 5 å€‹è©å½™
        category_words = thai_data['categories'][self.category]['words']
        
        
        
        selected_words = random.sample(category_words, min(5, len(category_words)))
        
        # åˆå§‹åŒ–å¡ç‰‡æ¸…å–®
        self.cards = []
        card_id = 1
        
        # ç‚ºæ¯å€‹è©å½™å‰µå»ºä¸€å°å¡ç‰‡ï¼ˆåœ–ç‰‡å¡å’ŒéŸ³é »å¡ï¼‰
        for word in selected_words:
            word_data = thai_data['basic_words'][word]
            
            # æ·»åŠ åœ–ç‰‡å¡
            self.cards.append({
                'id': card_id,
                'type': 'image',
                'content': word_data['image_url'],
                'match_id': card_id + 1,
                'word': word,
                'meaning': word,
                'thai': word_data['thai']
            })
            card_id += 1
            
            # æ·»åŠ éŸ³é »å¡
            self.cards.append({
                'id': card_id,
                'type': 'audio',
                'content': word_data['audio_url'],
                'match_id': card_id - 1,
                'word': word,
                'meaning': word,
                'thai': word_data['thai']
            })
            card_id += 1
        
        # æ´—ç‰Œ
        random.shuffle(self.cards)
        
        # é‡ç½®éŠæˆ²ç‹€æ…‹
        self.flipped_cards = []
        self.matched_pairs = []
        self.attempts = 0
        self.start_time = datetime.now()
        self.end_time = None
        self.pending_reset = False
        
        logger.info(f"Initialized memory card game, Category: {self.category}ï¼ŒNumber of cards: {len(self.cards)}")
        return self.cards
    
    def flip_card(self, card_id):
        """ç¿»è½‰å¡ç‰‡ä¸¦æª¢æŸ¥é…å°"""
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡ç½®å…ˆå‰ä¸åŒ¹é…çš„å¡ç‰‡
        if self.pending_reset:
            logger.info("Resetting previously unmatched cards")
            self.flipped_cards = []
            self.pending_reset = False
        
        # å°‹æ‰¾å¡ç‰‡
        card = next((c for c in self.cards if c['id'] == card_id), None)
        if not card:
            logger.warning(f"Card not found ID: {card_id}")
            return None, "Card does not exist", False, None
        
        # æª¢æŸ¥å¡ç‰‡æ˜¯å¦å·²ç¶“é…å°
        if card_id in [c['id'] for pair in self.matched_pairs for c in pair]:
            logger.warning(f"Card{card_id} is already matched")
            return self.get_game_state(), "Card is already matched", False, None
        
        # æª¢æŸ¥å¡ç‰‡æ˜¯å¦å·²ç¶“ç¿»è½‰
        if card_id in [c['id'] for c in self.flipped_cards]:
            logger.warning(f"Card {card_id}is already flipped")
            return self.get_game_state(), "Card is already flipped", False, None
        
        # æ·»åŠ åˆ°ç¿»è½‰å¡ç‰‡åˆ—è¡¨
        self.flipped_cards.append(card)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ’­æ”¾éŸ³é »
        should_play_audio = False
        audio_url = None
        if card['type'] == 'audio':
            should_play_audio = True
            word = card['word']
            if word in thai_data['basic_words'] and 'audio_url' in thai_data['basic_words'][word]:
                audio_url = thai_data['basic_words'][word]['audio_url']
        
        # å¦‚æœç¿»è½‰äº†å…©å¼µå¡ç‰‡ï¼Œæª¢æŸ¥æ˜¯å¦åŒ¹é…
        result = "Continue game"
        if len(self.flipped_cards) == 2:
            self.attempts += 1
            card1, card2 = self.flipped_cards
            
            # æª¢æŸ¥æ˜¯å¦é…å°
            if card1['match_id'] == card2['id'] and card2['match_id'] == card1['id']:
                # é…å°æˆåŠŸ
                self.matched_pairs.append(self.flipped_cards.copy())
                result = f"Match successfulï¼{card1['word']} - {card1['thai']}"
                logger.info(f"Cards matched successfully: {card1['id']} and {card2['id']}")
                # é…å°æˆåŠŸæ‰æ¸…ç©ºç¿»è½‰å¡ç‰‡åˆ—è¡¨
                self.flipped_cards = []
            else:
                # é…å°å¤±æ•— - è¨­ç½®æ¨™è¨˜è€Œä¸æ˜¯ç«‹å³æ¸…ç©ºç¿»è½‰å¡ç‰‡åˆ—è¡¨
                result = "Match failed, please try again"
                logger.info(f"Cards match failed: {card1['id']} and {card2['id']}")
                self.pending_reset = True
                # ä¸è¦åœ¨é€™è£¡æ¸…ç©º self.flipped_cardsï¼Œé€™æ¨£å¡ç‰‡æœƒä¿æŒç¿»é–‹ç‹€æ…‹
        
        # æª¢æŸ¥éŠæˆ²æ˜¯å¦çµæŸ
        if len(self.matched_pairs) * 2 == len(self.cards):
            self.end_time = datetime.now()
            result = self.get_end_result()
            logger.info("Memory card game finished")
        
        # æª¢æŸ¥æ˜¯å¦è¶…æ™‚
        elif self.start_time:
            elapsed_time = (datetime.now() - self.start_time).total_seconds()
            if elapsed_time > self.time_limit:
                self.end_time = datetime.now()
                result = "Time's up!" + self.get_end_result()
                logger.info("Memory card game timed out")
        
        return self.get_game_state(), result, should_play_audio, audio_url
    
    def get_game_state(self):
        """ç²å–ç•¶å‰éŠæˆ²ç‹€æ…‹"""
        elapsed_time = 0
        if self.start_time:
            current_time = self.end_time if self.end_time else datetime.now()
            elapsed_time = (current_time - self.start_time).total_seconds()
        
        remaining_time = max(0, self.time_limit - elapsed_time)
        
        # è¨ˆç®—é¡åˆ¥åç¨±
        category_name = ""
        if self.category and self.category in thai_data['categories']:
            category_name = thai_data['categories'][self.category]['name']
        
        return {
            'cards': self.cards,
            'flipped_cards': [c['id'] for c in self.flipped_cards],
            'matched_pairs': [[c['id'] for c in pair] for pair in self.matched_pairs],
            'attempts': self.attempts,
            'elapsed_time': elapsed_time,
            'remaining_time': remaining_time,
            'is_completed': len(self.matched_pairs) * 2 == len(self.cards),
            'is_timeout': elapsed_time > self.time_limit,
            'category': self.category,
            'category_name': category_name,
            'pending_reset': self.pending_reset
        }
    
    def get_end_result(self):
        """ç²å–éŠæˆ²çµæŸçµæœ"""
        if not self.end_time:
            return "Game not finished yet"
        
        duration = (self.end_time - self.start_time).total_seconds()
        pairs_count = len(self.cards) // 2
        matched_count = len(self.matched_pairs)
        
        # è¨ˆç®—åˆ†æ•¸å’Œç­‰ç´š
        if duration > self.time_limit:
            # è¶…æ™‚æƒ…æ³
            if matched_count == pairs_count:
                message = "Although time is up, you found all the matchesï¼"
                level = "Nice tryï¼"
            else:
                message = f"Time's up! You found {matched_count}/{pairs_count} pairs."
                level = "Keep goingï¼"
        else:
            # æœªè¶…æ™‚æƒ…æ³
            if duration < 30:  # 30ç§’å…§å®Œæˆ
                level = "Amazing! Your memory is outstanding!"
            elif duration < 60:  # 60ç§’å…§å®Œæˆ
                level = "Great! Your memory is very strong!"
            else:
                level = "Well done! Keep practicing to improve your memory!"
                
            message = f"Game completed!\nPairs found: {matched_count}/{pairs_count} pairs\nAttempts: {self.attempts} times\nTime taken: {int(duration)} seconds"
        
        return f"{message}\n{level}"

# === è¨˜æ†¶ç¿»ç‰ŒéŠæˆ²è™•ç† ===
def handle_memory_game(user_id, message):
    """è™•ç†è¨˜æ†¶ç¿»ç‰ŒéŠæˆ²è¨Šæ¯"""
    user_data = user_data_manager.get_user_data(user_id)
    
    # åˆå§‹åŒ–éŠæˆ²ç‹€æ…‹
    if 'game_state' not in user_data:
        user_data['game_state'] = {}
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ´»å‹•çš„éŠæˆ²
    if 'memory_game' not in user_data['game_state']:
        user_data['game_state']['memory_game'] = MemoryGame()
    
    game = user_data['game_state']['memory_game']
    
    # è™•ç†éŠæˆ²æŒ‡ä»¤
    if message == "Start Memory Game":
        # é¡¯ç¤ºä¸»é¡Œé¸å–®
        quick_reply = QuickReply(
            items=[
                QuickReplyButton(action=MessageAction(label='Daily Phrases', text='Memory Game Topic: Daily Phrases')),
                QuickReplyButton(action=MessageAction(label='Numbers', text='Memory Game Topic: Numbers')),
                QuickReplyButton(action=MessageAction(label='Animals', text='Memory Game Topic: Animals')),
                QuickReplyButton(action=MessageAction(label='Food', text='Memory Game Topic: Food')),
                QuickReplyButton(action=MessageAction(label='Transportation', text='Memory Game Topic: Transportation'))
            ]
        )
        
        return TextSendMessage(
          text="ğŸ® Memory Card Game\n\nGame Rules:\n1. Flip the cards to find matching image and pronunciation pairs\n2. You have 1 minute and 30 seconds to complete the game\n3. The faster you finish, the better your rating\n\nPlease choose a topic to begin:",
            quick_reply=quick_reply
        )
    
    elif message.startswith("Memory Game Topic" \
    ":"):
        category = message.split(":", 1)[1] if ":" in message else ""
        logger.info(f"Received memory game topic selection: '{category}'")
        
        # è½‰æ›æˆè‹±æ–‡éµå€¼
        category_map = {
            "Daily Phrases": "daily_phrases",
            "Numbers": "numbers",
            "Animals": "animals",
            "Food": "food",
            "Transportation": "transportation"
        }
        logger.info(f"Available topic mapping: {list(category_map.keys())}")
        
        if category in category_map:
            eng_category = category_map[category]
            logger.info(f"Topic mapping successful: {category} -> {eng_category}")
            
            # æª¢æŸ¥ thai_data æ˜¯å¦åŒ…å«è©²é¡åˆ¥
            if eng_category in thai_data['categories']:
                logger.info(f"Found category {eng_category}in thai_data")
                # åˆå§‹åŒ–éŠæˆ²
                cards = game.initialize_game(eng_category)
                
                # å‰µå»ºéŠæˆ²ç•«é¢ (ä½¿ç”¨ Flex Message)
                return create_flex_memory_game(cards, game.get_game_state(), user_id)
            else:
                logger.error(f"Category '{eng_category}' not found in thai_data")
                return TextSendMessage(text=f"Sorry, the category '{category}' was not found in the data. Please contact the administrator.")
        else:
            logger.warning(f"Unrecognized topic: {category}")
            return TextSendMessage(text="Sorry, the selected topic could not be recognized. Please choose again.")
    
    elif message.startswith("Flip Card:"):
        try:
            card_id = int(message.split(":")[1]) if ":" in message else -1
            logger.info(f"User clicked card number: {card_id}")
            
            # ç¿»é–‹å¡ç‰‡
            game_state, result, should_play_audio, audio_url = game.flip_card(card_id)
            
            # å„²å­˜è‡¨æ™‚æ•¸æ“šç”¨æ–¼è¨ªå•éŠæˆ²çµæœ
            temp_data = user_data_manager.get_user_data('temp')
            if 'game_state' not in temp_data:
                temp_data['game_state'] = {}
            temp_data['game_state']['memory_game'] = game
            
            # æº–å‚™å›æ‡‰è¨Šæ¯
            messages = []
            
            # æ·»åŠ æ–‡å­—çµæœ
            messages.append(TextSendMessage(text=result))
            
            # å¦‚æœéœ€è¦æ’­æ”¾éŸ³é »ï¼Œæ·»åŠ éŸ³é »æ¶ˆæ¯
            if should_play_audio and audio_url:
                logger.info(f"Preparing to play audio: {audio_url}")
                messages.append(
                    AudioSendMessage(
                        original_content_url=audio_url,
                        duration=3000  # å‡è¨­éŸ³è¨Šé•·åº¦ç‚º3ç§’
                    )
                )
            
            # å¦‚æœéŠæˆ²é‚„åœ¨é€²è¡Œä¸­ä¸”æ²’æœ‰è¶…æ™‚
            if game_state and not game_state.get('is_completed', False) and not game_state.get('is_timeout', False):
                # è¿”å›æ›´æ–°å¾Œçš„éŠæˆ²ç•«é¢
                messages.append(create_flex_memory_game(game.cards, game_state, user_id))
                return messages
            else:
                # éŠæˆ²çµæŸæˆ–è¶…æ™‚ï¼Œé¡¯ç¤ºçµæœ
                messages.append(
                    TextSendMessage(
                        text="Game over! Would you like to play again",
                        quick_reply=QuickReply(
                            items=[
                                QuickReplyButton(action=MessageAction(label='Play Again', text='Start MemoryGame')),
                                QuickReplyButton(action=MessageAction(label='Back to Main Menu', text='Back to Main Menu'))
                            ]
                        )
                    )
                )
                return messages
        except Exception as e:
            logger.error(f"Error occurred while processing card flip request: {str(e)}")
            return TextSendMessage(text=f"An error occurred while processing your card flip: {str(e)}\nPlease try again or select 'Back to Main Menu'.")
    
    elif message.startswith("Play Audio:"):
        word = message.split(":", 1)[1] if ":" in message else ""
        if word in thai_data['basic_words']:
            word_data = thai_data['basic_words'][word]
            if 'audio_url' in word_data and word_data['audio_url']:
                # ç²å–éŠæˆ²ç‹€æ…‹
                game_state = game.get_game_state()
                
                # ç™¼é€éŸ³é »å¾Œé¡¯ç¤ºéŠæˆ²ç•«é¢
                messages = [
                    AudioSendMessage(
                        original_content_url=word_data['audio_url'],
                        duration=3000  # å‡è¨­éŸ³è¨Šé•·åº¦ç‚º3ç§’
                    ),
                    create_flex_memory_game(game.cards, game_state, user_id)
                ]
                return messages
        
        return TextSendMessage(text="Sorry, the audio could not be played.")
    
    # é»˜èªå›å‚³
    return TextSendMessage(text="Please select 'Start MemoryGame' to begin a new game.")

def create_flex_memory_game(cards, game_state, user_id):
    """å‰µå»º Flex Message çš„è¨˜æ†¶ç¿»ç‰ŒéŠæˆ²ç•Œé¢"""
    from linebot.models import FlexSendMessage, TextSendMessage

    bubbles = []
    try:
        attempts = game_state.get('attempts', 0)
        remaining_time = int(game_state.get('remaining_time', 0))
        category_name = game_state.get('category_name', 'Unknown')
        is_completed = game_state.get('is_completed', False)
        is_timeout = game_state.get('is_timeout', False)

        matched_ids = [c for pair in game_state.get('matched_pairs', []) for c in pair]
        flipped_ids = game_state.get('flipped_cards', [])

        # éŠæˆ²è³‡è¨Šå¡ç‰‡
        info_bubble = {
            "type": "bubble",
            "header": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": "Thai Memory Card Game", "weight": "bold", "size": "xl", "color": "#ffffff"},
                    {"type": "text", "text": category_name, "size": "md", "color": "#ffffff"}
                ],
                "backgroundColor": "#4A86E8",
                "paddingBottom": "10px"
            },
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "box",
                        "layout": "horizontal",
                        "justifyContent":"center",
                        "contents": [
                            {"type": "text", "text": "â±ï¸Time Remaining:", "size": "sm", "color": "#555555", "flex": 2},
                            {"type": "text", "text": f"{remaining_time} sec", "size": "sm", "color": "#111111", "flex": 1}
                        ]
                    }
                ]
            }
        }
        bubbles.append(info_bubble)

        # å¡ç‰‡è¡Œæ’åˆ—ï¼Œæ¯åˆ—æœ€å¤š 4 å¼µå¡
        card_rows = [cards[i:i+4] for i in range(0, len(cards), 4)]
        for row_cards in card_rows:
            card_contents = []
            for card in row_cards:
                card_id = card['id']
                is_matched = card_id in matched_ids
                is_flipped = card_id in flipped_ids

                if is_matched or is_flipped:
                    if card['type'] == 'image':
                        card_box = {
                            "type": "box",
                            "layout": "vertical",
                            "width": "60px",
                            "height": "80px",
                            "backgroundColor": "#E6F5FF",
                            "cornerRadius": "4px",
                            "borderWidth": "1px",
                            "borderColor": "#AAAAAA",
                            "contents": [
                                {"type": "image", "url": card['content'], "size": "full", "aspectMode": "cover", "aspectRatio": "1:1"},
                                {"type": "text", "text": card['word'], "size": "xxs", "align": "center", "wrap": True, "maxLines": 2}
                            ]
                        }
                    else:
                        card_box = {
                            "type": "box",
                            "layout": "vertical",
                            "width": "60px",
                            "height": "80px",
                            "backgroundColor": "#FFF4E6",
                            "cornerRadius": "4px",
                            "borderWidth": "1px",
                            "borderColor": "#AAAAAA",
                            "contents": [
                                {"type": "text", "text": "ğŸµ", "size": "lg", "align": "center", "color": "#FF6B6E"},
                                {"type": "text", "text": card['thai'], "size": "xxs", "align": "center", "wrap": True, "maxLines": 2}
                            ],
                            "action": {"type": "message", "text": f"Play Audio:{card['word']}"}
                        }
                else:
                    back_icon = "ğŸ–¼ï¸" if card['type'] == "image" else "ğŸ§"
                    back_color = "#4A86E8" if card['type'] == "image" else "#FFA94D"
                    card_box = {
                        "type": "box",
                        "layout": "vertical",
                        "width": "60px",
                        "height": "80px",
                        "backgroundColor": back_color,
                        "cornerRadius": "4px",
                        "borderWidth": "1px",
                        "borderColor": "#0B5ED7",
                        "contents": [
                            {"type": "text", "text": back_icon, "color": "#FFFFFF", "align": "center", "gravity": "center", "size": "xl"},
                            {"type": "text", "text": f"{card_id}", "color": "#FFFFFF", "align": "center", "size": "sm"}
                        ],
                        "action": {"type": "message", "text": f"Flip Card:{card_id}"}
                    }

                card_contents.append(card_box)

            row_bubble = {"type": "bubble", "body": {"type": "box", "layout": "horizontal", "contents": card_contents}}
            bubbles.append(row_bubble)

        flex_message = {"type": "carousel", "contents": bubbles}
        return FlexSendMessage(alt_text="Thai Memory Card Game", contents=flex_message)

    except Exception as e:
        import logging
        logging.getLogger().error(f"Error occurred while creating Flex Message: {str(e)}")
        return TextSendMessage(text="The game display encountered an issue. Please try again later.")

    # âœ… è€ƒè©¦æŒ‡ä»¤éæ¿¾ï¼ˆåªæœ‰åœ¨ç¬¦åˆæ ¼å¼æ‰åŸ·è¡Œï¼‰
    if text.startswith("Start") and "Exam" in text:
        result = handle_exam_message(event)
        if result:
            if isinstance(result, list):
                line_bot_api.reply_message(event.reply_token, result)
        else:
            line_bot_api.reply_message(event.reply_token, [result])
        return




    # æ›´æ–°ç”¨æˆ¶æ´»èºç‹€æ…‹
    user_data_manager.update_streak(user_id)

    
    # æ’­æ”¾éŸ³é »è«‹æ±‚
    if text.startswith("Play Audio:"):
        word = text[5:]  # æå–è©å½™
        if word in thai_data['basic_words']:
            word_data = thai_data['basic_words'][word]
            if 'audio_url' in word_data and word_data['audio_url']:
                line_bot_api.reply_message(
                    event.reply_token,
                    AudioSendMessage(
                        original_content_url=word_data['audio_url'],
                        duration=3000  # å‡è¨­éŸ³è¨Šé•·åº¦ç‚º3ç§’
                    )
                )
                return
    
    # ä¸»é¸å–®èˆ‡åŸºæœ¬å°èˆª
    if text == "Start Learning" or text == "Back to Main Menu":
        exam_sessions.pop(user_id, None)  # â—ï¸æ¸…é™¤è€ƒè©¦ç‹€æ…‹ï¼Œé¿å…å¹²æ“¾
        line_bot_api.reply_message(event.reply_token, show_main_menu())
    
    # é¸æ“‡ä¸»é¡Œ
    elif text == "Select Topic":
        line_bot_api.reply_message(event.reply_token, show_category_menu())
    
    # ä¸»é¡Œé¸æ“‡è™•ç†
    elif text.startswith("Topic:"):
        category = text[3:]  # å–å‡ºä¸»é¡Œåç¨±
        # è½‰æ›æˆè‹±æ–‡éµå€¼
        category_map = {
            "Daily Phrases": "daily_phrases",
            "Numbers": "numbers",
            "Animals": "animals",
            "Food": "food",
            "Transportation": "transportation"
        }
        if category in category_map:
            eng_category = category_map[category]
            user_data['current_category'] = eng_category
            messages = start_image_learning(user_id, eng_category)
            line_bot_api.reply_message(event.reply_token, messages)
        else:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="Sorry, the selected topic could not be recognized. Please choose again.")
            )
    
    # å­¸ç¿’æ¨¡å¼é¸æ“‡
    elif text == "Vocabulary":
        messages = start_image_learning(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Pronunciation drill":
        messages = start_echo_practice(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Tone Learning":
        messages = start_tone_learning(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    # é€²åº¦èˆ‡å°èˆªæ§åˆ¶
    elif text == "Next Word":
        # å¦‚æœæœ‰ç•¶å‰ä¸»é¡Œï¼Œåœ¨åŒä¸€ä¸»é¡Œä¸­é¸æ“‡æ–°è©å½™
        if user_data.get('current_category'):
            category = user_data['current_category']
            user_data['current_vocab'] = random.choice(thai_data['categories'][category]['words'])
        else:
            # å¦å‰‡æ¸…é™¤ç•¶å‰è©å½™ï¼Œéš¨æ©Ÿé¸æ“‡
            user_data['current_vocab'] = None
        
        messages = start_image_learning(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Learning Progress":
        progress_message = show_learning_progress(user_id)
        line_bot_api.reply_message(event.reply_token, progress_message)
    
    elif text == "Practice Weak Words":
        # æ‰¾å‡ºè©•åˆ†æœ€ä½çš„è©å½™é€²è¡Œç·´ç¿’
        if not user_data.get('vocab_mastery') or len(user_data['vocab_mastery']) == 0:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="You don't have enough learning history yet. Please start with some vocabulary and pronunciation practice!")
            )
            return
            
        # æ‰¾å‡ºåˆ†æ•¸æœ€ä½çš„è©å½™
        worst_word = min(user_data['vocab_mastery'].items(), 
                      key=lambda x: sum(x[1]['scores'])/len(x[1]['scores']) if x[1]['scores'] else 100)
        
        # è¨­ç½®ç‚ºç•¶å‰è©å½™ä¸¦å•Ÿå‹•ç·´ç¿’
        user_data['current_vocab'] = worst_word[0]
        messages = start_echo_practice(user_id)
        line_bot_api.reply_message(event.reply_token, messages)
    
    elif text == "Learning Calendar":
        # é¡¯ç¤ºç”¨æˆ¶çš„å­¸ç¿’æ—¥æ›†å’Œé€£çºŒå­¸ç¿’å¤©æ•¸
        streak = user_data.get('streak', 0)
        last_active = user_data.get('last_active', 'Not started yet')
        
        calendar_message = f"ğŸ“…Your Learning Recordï¼š\n\n"
        calendar_message += f"ğŸ”¥ Consecutive Learning Days: {streak} days\n"
        calendar_message += f"ğŸ•“ Last Active Date: {last_active}\n\n"
        calendar_message += "Keep up your learning motivation! A little every day will steadily improve your Thai skills."
        
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=calendar_message)
        )
    elif text == "Exam Mode":
        quick_reply = QuickReply(
            items=[
                QuickReplyButton(action=MessageAction(label='Daily Phrases', text='Start Daily Phrases Exam')),
                QuickReplyButton(action=MessageAction(label='Numbers', text='Start Numbers Exam')),
                QuickReplyButton(action=MessageAction(label='Animals', text='Start Animals Exam')),
                QuickReplyButton(action=MessageAction(label='Food', text='Start Food Exam')),
                QuickReplyButton(action=MessageAction(label='Transportation', text='Start Transportation Exam')),
                QuickReplyButton(action=MessageAction(label='Comprehensive Exam', text='Start Full Exam'))
            ]
        )
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(
                text="Please select a category for the exam:",
                quick_reply=quick_reply
            )
        )
        return


    else:
        # é»˜èªå›è¦†
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="Please select 'Start Learning' or use the menu button to begin your Thai learning journey.")
        )
import threading
import time  # âœ… åŠ ä¸Šé€™è¡Œ

# å®šæœŸæ¸…ç†è‡¨æ™‚æª”æ¡ˆå‡½å¼
def cleanup_temp_files():
    """æ¸…ç†è‡¨æ™‚æª”æ¡ˆ"""
    try:
        temp_dir = os.environ.get('TEMP', '/tmp')
        audio_dir = os.path.join(temp_dir, 'temp_audio')
        
        if not os.path.exists(audio_dir):
            return
            
        now = datetime.now()
        for filename in os.listdir(audio_dir):
            if not filename.startswith('temp_'):
                continue
                
            file_path = os.path.join(audio_dir, filename)
            if os.path.isfile(file_path):
                mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                if (now - mtime).total_seconds() > 3600:
                    try:
                        os.remove(file_path)
                        logger.info(f"Cleaned up temporary file: {file_path}")
                    except:
                        pass
    except Exception as e:
        logger.error(f"Failed to clean up temporary files: {str(e)}")

# èƒŒæ™¯åŸ·è¡Œæ¸…ç†ï¼šæ¯ 30 åˆ†é˜è·‘ä¸€æ¬¡
def periodic_cleanup():
    while True:
        time.sleep(1800)  # æ¯ 30 åˆ†é˜åŸ·è¡Œ
        cleanup_temp_files()

# å•Ÿå‹•åŸ·è¡Œç·’
cleanup_thread = threading.Thread(target=periodic_cleanup, daemon=True)
cleanup_thread.start()

    # ä¸»ç¨‹åºå…¥å£ (æ”¾åœ¨æœ€å¾Œ)
if __name__ == "__main__":
    # å•Ÿå‹• Flask æ‡‰ç”¨ï¼Œä½¿ç”¨ç’°å¢ƒè®Šæ•¸è¨­å®šçš„ç«¯å£æˆ–é»˜èª5000
    port = int(os.environ.get('PORT', 5000))
    logger.info(f"Application started on port  {port}")
    app.run(host='0.0.0.0', port=port)
    
    